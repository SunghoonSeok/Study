'''
train loss는 줄어드는데 test/val loss는 어느순간 올라가거나 요동친다.
그렇다면 과적합일 확률이 농후하다.
과적합이 있으면 대충만든 모델보다도 정확도가 떨어질수 있다.

과적합 방지

1. 훈련 데이터를 늘린다.
2. feature를 줄인다. (너무많은걸 줄이는거지 중요한걸 날리면 안돼)
3. regularization(정규화)
4. Dropout(딥러닝전용)

5?. 앙상블? 통상 2~5% 향상이 있다고 하는 놈들이 있다. (검증 안됨)

'''