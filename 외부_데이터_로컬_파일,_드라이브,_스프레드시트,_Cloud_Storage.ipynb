{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "외부 데이터: 로컬 파일, 드라이브, 스프레드시트, Cloud Storage",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunghoonSeok/Study/blob/master/%EC%99%B8%EB%B6%80_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%A1%9C%EC%BB%AC_%ED%8C%8C%EC%9D%BC%2C_%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C%2C_%EC%8A%A4%ED%94%84%EB%A0%88%EB%93%9C%EC%8B%9C%ED%8A%B8%2C_Cloud_Storage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z2jcRKwUHqV"
      },
      "source": [
        "이 노트북에서는 외부 소스의 데이터를 로드 및 저장하는 레시피를 이용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "dHBHIPe5Qh0P",
        "outputId": "62dcb197-bf25-4a04-9ea7-b38952340da4"
      },
      "source": [
        "from google.colab import files\r\n",
        "myfile = files.upload()\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9df3d278-b055-4690-a0ed-1966a1bf76c7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9df3d278-b055-4690-a0ed-1966a1bf76c7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving KODEX 코스닥150 선물인버스.csv to KODEX 코스닥150 선물인버스.csv\n",
            "Saving 삼성전자.csv to 삼성전자.csv\n",
            "Saving 삼성전자0115.csv to 삼성전자0115.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ_f1CUnVulZ",
        "outputId": "78dd8eaf-cb74-4772-bb26-042facfecc22"
      },
      "source": [
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0d1zfCoQ5Lw",
        "outputId": "76c4240b-207b-4f1a-9040-684c2d246ae3"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import io\r\n",
        "# from pandas import read_csv\r\n",
        "# df = read_csv('c:/data/test/삼성전자.csv', index_col=0, header=0)\r\n",
        "df = pd.read_csv(io.BytesIO(myfile['삼성전자.csv']), index_col=0, header=0, encoding='cp949')\r\n",
        "\r\n",
        "\r\n",
        "print(df.shape) # (2400, 14)\r\n",
        "#Index(['시가', '고가', '저가', '종가', '등락률', '거래량', '금액(백만)', '신용비', '개인', '기관',\r\n",
        "#       '외인(수량)', '외국계', '프로그램', '외인비']\r\n",
        "\r\n",
        "# str -> int, 불필요한 행 제거\r\n",
        "df = df.drop(['2018-05-03','2018-05-02','2018-04-30'])\r\n",
        "df['시가'] =df['시가'].str.replace(',','').astype('int64')\r\n",
        "df['고가'] =df['고가'].str.replace(',','').astype('int64')\r\n",
        "df['저가'] =df['저가'].str.replace(',','').astype('int64')\r\n",
        "df['종가'] =df['종가'].str.replace(',','').astype('int64')\r\n",
        "df['거래량'] =df['거래량'].str.replace(',','').astype('int64')\r\n",
        "df['금액(백만)'] =df['금액(백만)'].str.replace(',','').astype('int64')\r\n",
        "df['개인'] =df['개인'].str.replace(',','').astype('int64')\r\n",
        "df['기관'] =df['기관'].str.replace(',','').astype('int64')\r\n",
        "df['외인(수량)'] =df['외인(수량)'].str.replace(',','').astype('int64')\r\n",
        "df['외국계'] =df['외국계'].str.replace(',','').astype('int64')\r\n",
        "df['프로그램'] =df['프로그램'].str.replace(',','').astype('int64')\r\n",
        "print(df.shape)\r\n",
        "\r\n",
        "# 데이터 추가, str -> float\r\n",
        "# df2 = read_csv('c:/data/test/삼성전자0115.csv', encoding='cp949', index_col=0, header=0, thousands=',')\r\n",
        "df2 = pd.read_csv(io.BytesIO(myfile['삼성전자0115.csv']), encoding='cp949', index_col=0, header=0, thousands=',')\r\n",
        "df2 = df2.dropna()\r\n",
        "df2 = df2.drop(['전일비','Unnamed: 6'], axis=1)\r\n",
        "\r\n",
        "# 중복 데이터 제거\r\n",
        "print(df.shape)\r\n",
        "df = df.drop(['2021-01-13'])\r\n",
        "df2 = df2.drop(df2.index[3:])\r\n",
        "print(df2.shape)\r\n",
        "\r\n",
        "\r\n",
        "# 액면분할 이전 데이터 주가변환\r\n",
        "df = df[::-1]\r\n",
        "df2 = df2[::-1]\r\n",
        "df.loc[:'2018-05-04','시가':'종가'] = (df.loc[:'2018-05-04','시가':'종가'])/50.\r\n",
        "df.loc[:'2018-05-04','거래량'] = (df.loc[:'2018-05-04','거래량'])*50.\r\n",
        "df.loc[:'2018-05-04','개인':'프로그램'] = (df.loc[:'2018-05-04','개인':'프로그램'])*50.\r\n",
        "\r\n",
        "# 데이터 병합\r\n",
        "df = pd.concat([df, df2], axis=0)\r\n",
        "print(df.shape)\r\n",
        "print(df.tail())\r\n",
        "\r\n",
        "# 타겟(y값) 설정\r\n",
        "dataset_y = df.iloc[:,0]\r\n",
        "df['Target'] = dataset_y\r\n",
        "\r\n",
        "# 불필요한 특성 제거\r\n",
        "# df = df.drop(['거래량','신용비','외인비'], axis=1)\r\n",
        "# df = df.drop(['개인','기관','외인(수량)','외국계','프로그램'], axis=1)\r\n",
        "print(df.shape)\r\n",
        "\r\n",
        "# csv -> npy 후 저장\r\n",
        "data = df.values\r\n",
        "print(data)\r\n",
        "# np.save('c:/data/test/samsung_jusik2.npy', arr=data)\r\n",
        "np.save('/content/drive/My Drive/data/test/samsung_jusik.npy', arr=data)\r\n",
        "\r\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2400, 14)\n",
            "(2397, 14)\n",
            "(2397, 14)\n",
            "(3, 14)\n",
            "(2399, 14)\n",
            "                 시가       고가       저가  ...        외국계       프로그램    외인비\n",
            "일자                                     ...                             \n",
            "2021-01-11  90000.0  96800.0  89500.0  ... -4979740.0 -6795684.0  55.59\n",
            "2021-01-12  90300.0  91400.0  87800.0  ... -2093652.0 -4498684.0  55.56\n",
            "2021/01/13  89800.0  91200.0  89100.0  ... -2774590.0 -2190774.0  55.52\n",
            "2021/01/14  88700.0  90000.0  88700.0  ...  2193784.0 -1091335.0  55.57\n",
            "2021/01/15  89800.0  91800.0  88000.0  ...  -261904.0 -3522801.0  55.57\n",
            "\n",
            "[5 rows x 14 columns]\n",
            "(2399, 15)\n",
            "[[ 1.782000e+04  1.784000e+04  1.732000e+04 ...  3.567500e+05\n",
            "   5.088000e+01  1.782000e+04]\n",
            " [ 1.706000e+04  1.750000e+04  1.706000e+04 ... -7.192500e+05\n",
            "   5.090000e+01  1.706000e+04]\n",
            " [ 1.778000e+04  1.832000e+04  1.772000e+04 ...  3.235600e+06\n",
            "   5.093000e+01  1.778000e+04]\n",
            " ...\n",
            " [ 8.980000e+04  9.120000e+04  8.910000e+04 ... -2.190774e+06\n",
            "   5.552000e+01  8.980000e+04]\n",
            " [ 8.870000e+04  9.000000e+04  8.870000e+04 ... -1.091335e+06\n",
            "   5.557000e+01  8.870000e+04]\n",
            " [ 8.980000e+04  9.180000e+04  8.800000e+04 ... -3.522801e+06\n",
            "   5.557000e+01  8.980000e+04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8pTtjPGXHyr",
        "outputId": "52e28221-29bc-4394-9f9b-e9ba2cb70c7b"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import io\r\n",
        "# from pandas import read_csv\r\n",
        "# df = read_csv('c:/data/test/삼성전자.csv', index_col=0, header=0)\r\n",
        "df = pd.read_csv(io.BytesIO(myfile['KODEX 코스닥150 선물인버스.csv']), index_col=0, header=0, encoding='cp949', thousands=',')\r\n",
        "\r\n",
        "\r\n",
        "print(df.shape) # (2400, 14)\r\n",
        "#Index(['시가', '고가', '저가', '종가', '등락률', '거래량', '금액(백만)', '신용비', '개인', '기관',\r\n",
        "#       '외인(수량)', '외국계', '프로그램', '외인비']\r\n",
        "\r\n",
        "# # str -> int, 불필요한 행 제거\r\n",
        "df = df.drop(['2018/05/03','2018/05/02','2018/04/30'])\r\n",
        "# df['시가'] =df['시가'].str.replace(',','').astype('int64')\r\n",
        "# df['고가'] =df['고가'].str.replace(',','').astype('int64')\r\n",
        "# df['저가'] =df['저가'].str.replace(',','').astype('int64')\r\n",
        "# df['종가'] =df['종가'].str.replace(',','').astype('int64')\r\n",
        "# df['거래량'] =df['거래량'].str.replace(',','').astype('int64')\r\n",
        "# df['금액(백만)'] =df['금액(백만)'].str.replace(',','').astype('int64')\r\n",
        "# df['개인'] =df['개인'].str.replace(',','').astype('int64')\r\n",
        "# df['기관'] =df['기관'].str.replace(',','').astype('int64')\r\n",
        "# df['외인(수량)'] =df['외인(수량)'].str.replace(',','').astype('int64')\r\n",
        "# df['외국계'] =df['외국계'].str.replace(',','').astype('int64')\r\n",
        "# df['프로그램'] =df['프로그램'].str.replace(',','').astype('int64')\r\n",
        "# print(df.shape)\r\n",
        "\r\n",
        "# 데이터 추가, str -> float\r\n",
        "# df2 = read_csv('c:/data/test/삼성전자0115.csv', encoding='cp949', index_col=0, header=0, thousands=',')\r\n",
        "# df2 = pd.read_csv(io.BytesIO(myfile['삼성전자0115.csv']), encoding='cp949', index_col=0, header=0, thousands=',')\r\n",
        "df = df.dropna()\r\n",
        "df = df.drop(['전일비','Unnamed: 6'], axis=1)\r\n",
        "\r\n",
        "# # 중복 데이터 제거\r\n",
        "# print(df.shape)\r\n",
        "# df = df.drop(['2021-01-13'])\r\n",
        "# df2 = df2.drop(df2.index[3:])\r\n",
        "# print(df2.shape)\r\n",
        "df = df[::-1]\r\n",
        "\r\n",
        "# # 액면분할 이전 데이터 주가변환\r\n",
        "# df = df[::-1]\r\n",
        "# df2 = df2[::-1]\r\n",
        "# df.loc[:'2018-05-04','시가':'종가'] = (df.loc[:'2018-05-04','시가':'종가'])/50.\r\n",
        "# df.loc[:'2018-05-04','거래량'] = (df.loc[:'2018-05-04','거래량'])*50.\r\n",
        "# df.loc[:'2018-05-04','개인':'프로그램'] = (df.loc[:'2018-05-04','개인':'프로그램'])*50.\r\n",
        "\r\n",
        "# # 데이터 병합\r\n",
        "# df = pd.concat([df, df2], axis=0)\r\n",
        "# print(df.shape)\r\n",
        "# print(df.tail())\r\n",
        "\r\n",
        "# # 타겟(y값) 설정\r\n",
        "# dataset_y = df.iloc[:,0]\r\n",
        "# df['Target'] = dataset_y\r\n",
        "\r\n",
        "# 불필요한 특성 제거\r\n",
        "# df = df.drop(['거래량','신용비','외인비'], axis=1)\r\n",
        "# df = df.drop(['개인','기관','외인(수량)','외국계','프로그램'], axis=1)\r\n",
        "print(df.shape)\r\n",
        "\r\n",
        "# csv -> npy 후 저장\r\n",
        "data = df.values\r\n",
        "print(data)\r\n",
        "# np.save('c:/data/test/samsung_jusik2.npy', arr=data)\r\n",
        "np.save('/content/drive/My Drive/data/test/kodex_jusik.npy', arr=data)\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1088, 16)\n",
            "(1085, 14)\n",
            "[[1.0000e+04 1.0000e+04 9.8650e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
            " [9.8900e+03 1.0025e+04 9.8650e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
            " [1.0020e+04 1.0025e+04 9.9450e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
            " ...\n",
            " [4.3700e+03 4.4100e+03 4.3350e+03 ... 0.0000e+00 0.0000e+00 4.4000e+00]\n",
            " [4.4000e+03 4.4400e+03 4.3800e+03 ... 0.0000e+00 0.0000e+00 4.5400e+00]\n",
            " [4.4200e+03 4.5450e+03 4.4050e+03 ... 0.0000e+00 0.0000e+00 4.5200e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cD9J1-TOYJTn",
        "outputId": "7f59deda-2f94-41e2-d00b-4288d8020c9c"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "# 1. 데이터\r\n",
        "data1 = np.load('/content/drive/My Drive/data/test/samsung_jusik.npy')\r\n",
        "data2 = np.load('/content/drive/My Drive/data/test/kodex_jusik.npy')\r\n",
        "\r\n",
        "x1 = data1[1314:,:-1]\r\n",
        "x2 = data2\r\n",
        "y = data1[1314:,-1]\r\n",
        "print(x1.shape, x2.shape)\r\n",
        "print(y.shape)\r\n",
        "\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scaler1 = MinMaxScaler()\r\n",
        "scaler1.fit(x1)\r\n",
        "x1 = scaler1.transform(x1)\r\n",
        "\r\n",
        "scaler2 = MinMaxScaler()\r\n",
        "scaler2.fit(x2)\r\n",
        "x2 = scaler2.transform(x2)\r\n",
        "\r\n",
        "size = 6\r\n",
        "\r\n",
        "def split_x(seq, size):\r\n",
        "    aaa = []\r\n",
        "    for i in range(len(seq)-size+1):\r\n",
        "        subset = seq[i : (i+size)]\r\n",
        "        aaa.append([item for item in subset])\r\n",
        "    print(type(aaa))\r\n",
        "    return np.array(aaa)\r\n",
        "x1_data = split_x(x1, size)\r\n",
        "x2_data = split_x(x2, size)\r\n",
        "\r\n",
        "x1 = x1_data[:-2,:,:]\r\n",
        "x2 = x2_data[:-2,:,:]\r\n",
        "\r\n",
        "size = 2\r\n",
        "y = split_x(y, 2)\r\n",
        "y = y[6:]\r\n",
        "print(x1.shape, x2.shape)\r\n",
        "print(y.shape)\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "x1_train, x1_test, x2_train, x2_test, y_train, y_test = train_test_split(x1, x2, y, train_size=0.8, shuffle=True, random_state=66)\r\n",
        "\r\n",
        "\r\n",
        "#2. 모델구성\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Dropout, Conv1D, Flatten, MaxPooling1D, GRU, SimpleRNN\r\n",
        "# inputs = Input(shape=(6, x.shape[2]))\r\n",
        "# dense1 = Conv1D(1000, 2, padding='same', activation='relu')(inputs)\r\n",
        "# dense1 = MaxPooling1D(pool_size=2)(dense1)\r\n",
        "# dense1 = Conv1D(500, 2, activation='relu')(dense1)\r\n",
        "# dense1 = Conv1D(400, 2,activation='relu')(dense1)\r\n",
        "# dense1 = Flatten()(dense1)\r\n",
        "\r\n",
        "\r\n",
        "# 모델 1\r\n",
        "input1 = Input(shape=(6,x1.shape[2]))\r\n",
        "dense1 = LSTM(512)(input1)\r\n",
        "dense1 = Dense(256)(dense1)\r\n",
        "dense1 = Dense(128)(dense1)\r\n",
        "dense1 = Dense(64)(dense1)\r\n",
        "dense1 = Dense(32)(dense1)\r\n",
        "dense1 = Dense(16)(dense1)\r\n",
        "dense1 = Dense(8)(dense1)\r\n",
        "dense1 = Dense(4)(dense1)\r\n",
        "dense1 = Dense(2)(dense1)\r\n",
        "\r\n",
        "\r\n",
        "# 모델 2\r\n",
        "input2 = Input(shape=(6,x2.shape[2]))\r\n",
        "dense2 = LSTM(128)(input2)\r\n",
        "dense2 = Dense(64)(dense2)\r\n",
        "dense2 = Dense(32)(dense2)\r\n",
        "dense2 = Dense(16)(dense2)\r\n",
        "dense2 = Dense(8)(dense2)\r\n",
        "dense2 = Dense(4)(dense2)\r\n",
        "dense2 = Dense(2)(dense2)\r\n",
        "\r\n",
        "\r\n",
        "from tensorflow.keras.layers import concatenate, Concatenate\r\n",
        "merge1 = concatenate([dense1, dense2])\r\n",
        "middle1 = Dense(128)(merge1)\r\n",
        "middle1 = Dense(64)(middle1)\r\n",
        "middle1 = Dense(32)(middle1)\r\n",
        "middle1 = Dense(16)(middle1)\r\n",
        "middle1 = Dense(8)(middle1)\r\n",
        "middle1 = Dense(4)(middle1)\r\n",
        "outputs = Dense(2)(middle1)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "model = Model(inputs=[input1,input2], outputs=outputs)\r\n",
        "\r\n",
        "\r\n",
        "#3. 컴파일, 훈련\r\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\r\n",
        "es = EarlyStopping(monitor='val_loss', patience=100, mode='auto')\r\n",
        "modelpath= '/content/drive/My Drive/data/test/modelcheckpoint/samsung_checkpoint_{val_loss:.4f}.hdf5'\r\n",
        "cp = ModelCheckpoint(modelpath, monitor='val_loss', save_best_only=True, mode='auto')\r\n",
        "model.fit([x1_train,x2_train], y_train, batch_size=64, epochs=1000, validation_split=0.2, callbacks=[cp, es])\r\n",
        "\r\n",
        "model.save('/content/drive/My Drive/data/test/samsung_model.h5')\r\n",
        "\r\n",
        "#4. 평가, 예측\r\n",
        "loss, mae = model.evaluate([x1_test,x2_test], y_test, batch_size=64)\r\n",
        "y_predict = model.predict([x1_test, x2_test])\r\n",
        "print(\"loss, mae : \", loss, mae)\r\n",
        "\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "def RMSE(y_test, y_predict):\r\n",
        "    return np.sqrt(mean_squared_error(y_test, y_predict))\r\n",
        "print(\"RMSE : \", RMSE(y_test, y_predict))\r\n",
        "\r\n",
        "from sklearn.metrics import r2_score\r\n",
        "r2 = r2_score(y_test, y_predict)\r\n",
        "print(\"R2 : \", r2)\r\n",
        "\r\n",
        "x1_pred = x1_data[-2:,:,:]\r\n",
        "x2_pred = x2_data[-2:,:,:]\r\n",
        "x1_pred = x1_pred.reshape(x1_pred.shape[0],6,x1_pred.shape[-1])\r\n",
        "x2_pred = x2_pred.reshape(x2_pred.shape[0],6,x2_pred.shape[-1])\r\n",
        "y_predict = model.predict([x1_pred,x2_pred])\r\n",
        "y_price = int(np.round(y_predict[-1]))\r\n",
        "\r\n",
        "# for i in range(1,(x_pred.shape[0])):\r\n",
        "#     subset = ([int(y_predict[i-1]),y[-(x_pred.shape[0])+i]])\r\n",
        "#     print(subset)\r\n",
        "\r\n",
        "\r\n",
        "print(\"익일 삼성 주가 : \", y_price, \"원\")\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1085, 14) (1085, 14)\n",
            "(1085,)\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "(1078, 6, 14) (1078, 6, 14)\n",
            "(1078, 2)\n",
            "Epoch 1/1000\n",
            "11/11 [==============================] - 10s 91ms/step - loss: 2342190314.6667 - mae: 47615.8197 - val_loss: 2296166656.0000 - val_mae: 47141.0234\n",
            "Epoch 2/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2024838282.6667 - mae: 44036.9639 - val_loss: 405551296.0000 - val_mae: 16035.8408\n",
            "Epoch 3/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 415020789.3333 - mae: 16725.3996 - val_loss: 226259056.0000 - val_mae: 12802.0400\n",
            "Epoch 4/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 165717913.3333 - mae: 10516.2899 - val_loss: 95274880.0000 - val_mae: 7412.6147\n",
            "Epoch 5/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 107614274.0000 - mae: 8004.6207 - val_loss: 96089216.0000 - val_mae: 7678.4038\n",
            "Epoch 6/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 90440900.6667 - mae: 7160.4549 - val_loss: 78415064.0000 - val_mae: 6118.6670\n",
            "Epoch 7/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 73903207.3333 - mae: 6175.6125 - val_loss: 76049848.0000 - val_mae: 5934.7925\n",
            "Epoch 8/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 76367315.3333 - mae: 6254.1910 - val_loss: 74503952.0000 - val_mae: 5937.3491\n",
            "Epoch 9/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 69519391.6667 - mae: 6168.1634 - val_loss: 74423992.0000 - val_mae: 6046.2529\n",
            "Epoch 10/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 70208190.3333 - mae: 6121.6732 - val_loss: 76237080.0000 - val_mae: 6255.5645\n",
            "Epoch 11/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 75274486.0000 - mae: 6410.1579 - val_loss: 74138760.0000 - val_mae: 5970.6895\n",
            "Epoch 12/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 79308076.6667 - mae: 6319.9003 - val_loss: 74117016.0000 - val_mae: 5953.1909\n",
            "Epoch 13/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 77410738.6667 - mae: 6419.7753 - val_loss: 74107416.0000 - val_mae: 5952.0571\n",
            "Epoch 14/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 70785425.3333 - mae: 6022.8714 - val_loss: 74873936.0000 - val_mae: 6119.3657\n",
            "Epoch 15/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 79771242.0000 - mae: 6505.6685 - val_loss: 74177720.0000 - val_mae: 6011.0317\n",
            "Epoch 16/1000\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 75033117.3333 - mae: 6389.6736 - val_loss: 77720008.0000 - val_mae: 6051.9580\n",
            "Epoch 17/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 84585311.3333 - mae: 6665.6632 - val_loss: 76873184.0000 - val_mae: 5997.8491\n",
            "Epoch 18/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 71286657.6667 - mae: 6118.1110 - val_loss: 78079480.0000 - val_mae: 6125.2324\n",
            "Epoch 19/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 77209512.6667 - mae: 6498.6563 - val_loss: 67210936.0000 - val_mae: 5587.5073\n",
            "Epoch 20/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 68705449.0000 - mae: 6045.9445 - val_loss: 53179948.0000 - val_mae: 5565.0029\n",
            "Epoch 21/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 46276949.3333 - mae: 5106.8539 - val_loss: 45146392.0000 - val_mae: 5055.2354\n",
            "Epoch 22/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 41659848.6667 - mae: 4717.8927 - val_loss: 42359748.0000 - val_mae: 4795.7427\n",
            "Epoch 23/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 43700655.6667 - mae: 4887.7842 - val_loss: 35448436.0000 - val_mae: 4729.9155\n",
            "Epoch 24/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 28463620.0000 - mae: 4211.4216 - val_loss: 34070680.0000 - val_mae: 4591.1431\n",
            "Epoch 25/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 29390436.3333 - mae: 4151.2894 - val_loss: 24937596.0000 - val_mae: 4043.8289\n",
            "Epoch 26/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 25712710.0000 - mae: 3889.5136 - val_loss: 25888828.0000 - val_mae: 3962.3281\n",
            "Epoch 27/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 22177507.8333 - mae: 3605.2688 - val_loss: 24923982.0000 - val_mae: 4050.4705\n",
            "Epoch 28/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 24728271.8333 - mae: 3846.9332 - val_loss: 28191368.0000 - val_mae: 4197.4751\n",
            "Epoch 29/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 25010909.0000 - mae: 3876.9772 - val_loss: 25290094.0000 - val_mae: 3947.8887\n",
            "Epoch 30/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 21341863.5000 - mae: 3479.0590 - val_loss: 22945378.0000 - val_mae: 3814.1011\n",
            "Epoch 31/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 20178394.6667 - mae: 3456.4025 - val_loss: 22145048.0000 - val_mae: 3664.7412\n",
            "Epoch 32/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 21916109.1667 - mae: 3552.6874 - val_loss: 22988380.0000 - val_mae: 3693.9358\n",
            "Epoch 33/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 20922195.0000 - mae: 3613.9354 - val_loss: 22296198.0000 - val_mae: 3579.5940\n",
            "Epoch 34/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 19244363.5000 - mae: 3361.0548 - val_loss: 21892140.0000 - val_mae: 3621.8088\n",
            "Epoch 35/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 18843584.5000 - mae: 3353.0375 - val_loss: 23012412.0000 - val_mae: 3795.1379\n",
            "Epoch 36/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 22339243.0000 - mae: 3504.8569 - val_loss: 20838724.0000 - val_mae: 3610.0061\n",
            "Epoch 37/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 19187909.6667 - mae: 3414.1479 - val_loss: 26810226.0000 - val_mae: 4202.3765\n",
            "Epoch 38/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 21154083.8333 - mae: 3682.9172 - val_loss: 21600056.0000 - val_mae: 3579.8455\n",
            "Epoch 39/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 18752729.9167 - mae: 3343.1628 - val_loss: 23177432.0000 - val_mae: 3794.9060\n",
            "Epoch 40/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 19670280.5000 - mae: 3321.8315 - val_loss: 18813944.0000 - val_mae: 3292.9629\n",
            "Epoch 41/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 17292039.5000 - mae: 3061.0306 - val_loss: 18498830.0000 - val_mae: 3285.7947\n",
            "Epoch 42/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 16403389.8333 - mae: 3070.4025 - val_loss: 18135040.0000 - val_mae: 3327.4893\n",
            "Epoch 43/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 16601875.9167 - mae: 3152.2975 - val_loss: 18376954.0000 - val_mae: 3337.0979\n",
            "Epoch 44/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 15689083.9167 - mae: 3053.9295 - val_loss: 18271178.0000 - val_mae: 3311.7476\n",
            "Epoch 45/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 16210802.7500 - mae: 2971.2908 - val_loss: 18203832.0000 - val_mae: 3301.9114\n",
            "Epoch 46/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16825185.1667 - mae: 3168.5906 - val_loss: 17364116.0000 - val_mae: 3290.1899\n",
            "Epoch 47/1000\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 17210177.5833 - mae: 3013.8561 - val_loss: 17583520.0000 - val_mae: 3325.3115\n",
            "Epoch 48/1000\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 14279914.6667 - mae: 2824.7364 - val_loss: 15951736.0000 - val_mae: 3147.3684\n",
            "Epoch 49/1000\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 15395784.8333 - mae: 2984.7657 - val_loss: 14774466.0000 - val_mae: 3090.4133\n",
            "Epoch 50/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 16058468.3333 - mae: 2993.6804 - val_loss: 15604109.0000 - val_mae: 3207.8779\n",
            "Epoch 51/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 15366556.0833 - mae: 2963.9745 - val_loss: 15413668.0000 - val_mae: 3124.6204\n",
            "Epoch 52/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 14470247.9167 - mae: 2830.8739 - val_loss: 15293080.0000 - val_mae: 3101.2427\n",
            "Epoch 53/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 13736171.8333 - mae: 2791.5823 - val_loss: 17902100.0000 - val_mae: 3321.9780\n",
            "Epoch 54/1000\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 14931436.5833 - mae: 2946.9125 - val_loss: 15794685.0000 - val_mae: 3189.6113\n",
            "Epoch 55/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 16569688.8333 - mae: 3023.1153 - val_loss: 19390990.0000 - val_mae: 3552.6594\n",
            "Epoch 56/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 14179018.8333 - mae: 2906.7943 - val_loss: 13428567.0000 - val_mae: 2922.2415\n",
            "Epoch 57/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 13347407.3333 - mae: 2673.8357 - val_loss: 13118597.0000 - val_mae: 2828.6523\n",
            "Epoch 58/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 10825486.8333 - mae: 2424.0163 - val_loss: 12663203.0000 - val_mae: 2819.1492\n",
            "Epoch 59/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 11813519.0833 - mae: 2622.8329 - val_loss: 11783390.0000 - val_mae: 2712.5676\n",
            "Epoch 60/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 11754551.5000 - mae: 2625.0119 - val_loss: 13012220.0000 - val_mae: 2846.8193\n",
            "Epoch 61/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 12817835.2500 - mae: 2571.4719 - val_loss: 12083110.0000 - val_mae: 2720.3616\n",
            "Epoch 62/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 16361332.6667 - mae: 2689.3293 - val_loss: 11014023.0000 - val_mae: 2612.9292\n",
            "Epoch 63/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9699310.0000 - mae: 2355.7162 - val_loss: 10778313.0000 - val_mae: 2557.6975\n",
            "Epoch 64/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 10508150.0000 - mae: 2439.3739 - val_loss: 12584448.0000 - val_mae: 2795.0601\n",
            "Epoch 65/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 10472428.5000 - mae: 2475.1465 - val_loss: 13706731.0000 - val_mae: 2923.1882\n",
            "Epoch 66/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 11986593.2500 - mae: 2686.0620 - val_loss: 13299093.0000 - val_mae: 2954.5518\n",
            "Epoch 67/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 12779877.0000 - mae: 2798.5302 - val_loss: 11328263.0000 - val_mae: 2714.1914\n",
            "Epoch 68/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 10804851.1667 - mae: 2508.5098 - val_loss: 9944220.0000 - val_mae: 2491.8210\n",
            "Epoch 69/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9563414.5000 - mae: 2337.7131 - val_loss: 10698432.0000 - val_mae: 2554.4622\n",
            "Epoch 70/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 10919960.2500 - mae: 2558.0239 - val_loss: 13195541.0000 - val_mae: 2930.1760\n",
            "Epoch 71/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 10397502.7500 - mae: 2447.8621 - val_loss: 9963095.0000 - val_mae: 2511.3740\n",
            "Epoch 72/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9286327.0000 - mae: 2309.5476 - val_loss: 11692374.0000 - val_mae: 2653.7773\n",
            "Epoch 73/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 12269778.0000 - mae: 2544.3326 - val_loss: 10227975.0000 - val_mae: 2502.4658\n",
            "Epoch 74/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 10915640.0833 - mae: 2296.3725 - val_loss: 11093642.0000 - val_mae: 2576.6677\n",
            "Epoch 75/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 14260616.0833 - mae: 2481.7796 - val_loss: 10531874.0000 - val_mae: 2607.7490\n",
            "Epoch 76/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 9237694.6667 - mae: 2329.5412 - val_loss: 9533871.0000 - val_mae: 2447.7671\n",
            "Epoch 77/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9506389.5417 - mae: 2337.5915 - val_loss: 13267856.0000 - val_mae: 2889.5356\n",
            "Epoch 78/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9294361.3333 - mae: 2250.9730 - val_loss: 8313788.0000 - val_mae: 2287.0813\n",
            "Epoch 79/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8726799.0417 - mae: 2267.9940 - val_loss: 8991182.0000 - val_mae: 2363.8057\n",
            "Epoch 80/1000\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 12673358.9167 - mae: 2246.9182 - val_loss: 8067795.5000 - val_mae: 2247.1726\n",
            "Epoch 81/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 9471871.6250 - mae: 2078.3955 - val_loss: 10354333.0000 - val_mae: 2521.1614\n",
            "Epoch 82/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 8960949.9583 - mae: 2109.2230 - val_loss: 8327561.5000 - val_mae: 2206.6216\n",
            "Epoch 83/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8069347.7917 - mae: 1985.7669 - val_loss: 8826080.0000 - val_mae: 2249.2173\n",
            "Epoch 84/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6690300.8750 - mae: 1930.5819 - val_loss: 7503085.5000 - val_mae: 2144.8804\n",
            "Epoch 85/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 11372759.2500 - mae: 2103.8267 - val_loss: 6824056.0000 - val_mae: 2033.7092\n",
            "Epoch 86/1000\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 11145244.0000 - mae: 1999.4871 - val_loss: 6814512.0000 - val_mae: 2037.4960\n",
            "Epoch 87/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5916859.8333 - mae: 1732.6328 - val_loss: 6493438.0000 - val_mae: 1999.9473\n",
            "Epoch 88/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 11243840.5000 - mae: 2027.1318 - val_loss: 11020146.0000 - val_mae: 2653.1545\n",
            "Epoch 89/1000\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 11322123.8333 - mae: 2250.3883 - val_loss: 6577391.5000 - val_mae: 2004.0083\n",
            "Epoch 90/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 10381055.7917 - mae: 2075.4190 - val_loss: 7668478.5000 - val_mae: 2202.8982\n",
            "Epoch 91/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 6410345.3750 - mae: 1864.5525 - val_loss: 6483323.0000 - val_mae: 1988.3713\n",
            "Epoch 92/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6417965.8333 - mae: 1923.4275 - val_loss: 8383587.0000 - val_mae: 2285.1145\n",
            "Epoch 93/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9349548.9583 - mae: 1989.2130 - val_loss: 7092077.0000 - val_mae: 2052.4187\n",
            "Epoch 94/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6364529.5000 - mae: 1758.5441 - val_loss: 7299590.0000 - val_mae: 2072.6836\n",
            "Epoch 95/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 7099003.8750 - mae: 1958.7944 - val_loss: 8344834.0000 - val_mae: 2218.2576\n",
            "Epoch 96/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8957694.0417 - mae: 1983.3105 - val_loss: 9927164.0000 - val_mae: 2432.7324\n",
            "Epoch 97/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8600486.2083 - mae: 2224.9482 - val_loss: 8166712.0000 - val_mae: 2179.9111\n",
            "Epoch 98/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7380326.4167 - mae: 1969.6252 - val_loss: 6252405.0000 - val_mae: 1967.8140\n",
            "Epoch 99/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6938207.5417 - mae: 1897.1604 - val_loss: 7893701.0000 - val_mae: 2299.1045\n",
            "Epoch 100/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9667486.5833 - mae: 1869.6309 - val_loss: 6497502.5000 - val_mae: 1933.2603\n",
            "Epoch 101/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4853464.8750 - mae: 1618.2209 - val_loss: 6737642.0000 - val_mae: 2022.1145\n",
            "Epoch 102/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8024476.4583 - mae: 1942.8287 - val_loss: 6255287.5000 - val_mae: 1944.7915\n",
            "Epoch 103/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 7484349.4583 - mae: 1857.6777 - val_loss: 5920395.5000 - val_mae: 1881.4160\n",
            "Epoch 104/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9860345.7917 - mae: 1866.6385 - val_loss: 6845246.0000 - val_mae: 2053.5955\n",
            "Epoch 105/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7103697.8750 - mae: 1880.7693 - val_loss: 6681182.0000 - val_mae: 1998.4252\n",
            "Epoch 106/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5144409.3333 - mae: 1661.1534 - val_loss: 6667387.5000 - val_mae: 2039.7778\n",
            "Epoch 107/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 11184305.8333 - mae: 2061.4624 - val_loss: 7407671.0000 - val_mae: 2149.1394\n",
            "Epoch 108/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6999359.0000 - mae: 1899.0309 - val_loss: 5384288.0000 - val_mae: 1850.8419\n",
            "Epoch 109/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4898500.5000 - mae: 1681.4776 - val_loss: 5640639.5000 - val_mae: 1857.3170\n",
            "Epoch 110/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5406869.5833 - mae: 1677.3861 - val_loss: 5444543.5000 - val_mae: 1808.1373\n",
            "Epoch 111/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 5330812.8333 - mae: 1656.7012 - val_loss: 5711992.0000 - val_mae: 1822.3965\n",
            "Epoch 112/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5873093.4167 - mae: 1682.6616 - val_loss: 5724094.5000 - val_mae: 1882.6364\n",
            "Epoch 113/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6410702.0000 - mae: 1701.0360 - val_loss: 5154823.0000 - val_mae: 1800.8073\n",
            "Epoch 114/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4373787.6875 - mae: 1527.6312 - val_loss: 5139806.5000 - val_mae: 1738.1766\n",
            "Epoch 115/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 6318874.0000 - mae: 1661.4516 - val_loss: 5117025.0000 - val_mae: 1810.2379\n",
            "Epoch 116/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4979203.1667 - mae: 1575.4211 - val_loss: 5162358.0000 - val_mae: 1782.8219\n",
            "Epoch 117/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4923813.3125 - mae: 1511.1612 - val_loss: 5006863.0000 - val_mae: 1750.9379\n",
            "Epoch 118/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4757536.1458 - mae: 1565.3581 - val_loss: 8497451.0000 - val_mae: 2270.1294\n",
            "Epoch 119/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7416136.4583 - mae: 2009.5199 - val_loss: 8087931.0000 - val_mae: 2290.8682\n",
            "Epoch 120/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10197292.6667 - mae: 1885.9159 - val_loss: 8749667.0000 - val_mae: 2339.6768\n",
            "Epoch 121/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 7266008.7917 - mae: 1948.8183 - val_loss: 7868889.0000 - val_mae: 2068.8259\n",
            "Epoch 122/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 5194245.2708 - mae: 1664.1973 - val_loss: 6863823.0000 - val_mae: 1943.9338\n",
            "Epoch 123/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6551097.6667 - mae: 1746.1860 - val_loss: 5403493.5000 - val_mae: 1769.5140\n",
            "Epoch 124/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6662154.3333 - mae: 1690.8995 - val_loss: 5065846.5000 - val_mae: 1787.6096\n",
            "Epoch 125/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6893775.1042 - mae: 1635.2447 - val_loss: 5876837.5000 - val_mae: 1896.8953\n",
            "Epoch 126/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7603416.5833 - mae: 1818.4795 - val_loss: 4769791.5000 - val_mae: 1743.5752\n",
            "Epoch 127/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4900237.3333 - mae: 1563.6955 - val_loss: 4163839.2500 - val_mae: 1596.0072\n",
            "Epoch 128/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8279581.4167 - mae: 1542.0999 - val_loss: 4308189.0000 - val_mae: 1624.6936\n",
            "Epoch 129/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 8103387.9167 - mae: 1483.0280 - val_loss: 5678962.5000 - val_mae: 1881.5592\n",
            "Epoch 130/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5292869.0208 - mae: 1589.0538 - val_loss: 4831725.0000 - val_mae: 1733.0825\n",
            "Epoch 131/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6540002.4583 - mae: 1589.9524 - val_loss: 4808813.0000 - val_mae: 1690.6431\n",
            "Epoch 132/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4273744.1458 - mae: 1516.3591 - val_loss: 4668840.0000 - val_mae: 1650.3710\n",
            "Epoch 133/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4443841.8750 - mae: 1544.9090 - val_loss: 4154213.0000 - val_mae: 1599.9563\n",
            "Epoch 134/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4763016.4375 - mae: 1546.4853 - val_loss: 5744470.0000 - val_mae: 1894.7002\n",
            "Epoch 135/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9426411.9583 - mae: 1797.2074 - val_loss: 5030338.5000 - val_mae: 1759.0693\n",
            "Epoch 136/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5650314.5833 - mae: 1635.5664 - val_loss: 4796480.5000 - val_mae: 1745.3008\n",
            "Epoch 137/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5959783.0417 - mae: 1549.1846 - val_loss: 4261336.5000 - val_mae: 1639.4409\n",
            "Epoch 138/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4601525.8958 - mae: 1521.1804 - val_loss: 4735063.5000 - val_mae: 1691.7894\n",
            "Epoch 139/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6024930.1042 - mae: 1463.9141 - val_loss: 4734277.5000 - val_mae: 1652.3671\n",
            "Epoch 140/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 6640530.8125 - mae: 1602.7567 - val_loss: 4982020.5000 - val_mae: 1709.1752\n",
            "Epoch 141/1000\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 5444219.5625 - mae: 1455.0247 - val_loss: 6317233.0000 - val_mae: 2040.7719\n",
            "Epoch 142/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6618508.5000 - mae: 1828.3435 - val_loss: 6970186.5000 - val_mae: 2136.3696\n",
            "Epoch 143/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5932457.9167 - mae: 1720.8752 - val_loss: 6278877.0000 - val_mae: 1988.6100\n",
            "Epoch 144/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6017351.9583 - mae: 1692.8405 - val_loss: 4942035.5000 - val_mae: 1778.6115\n",
            "Epoch 145/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7515055.2083 - mae: 1695.1629 - val_loss: 7905428.0000 - val_mae: 2243.5894\n",
            "Epoch 146/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 10617258.8333 - mae: 2014.1960 - val_loss: 4889639.0000 - val_mae: 1733.4985\n",
            "Epoch 147/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4452681.2083 - mae: 1550.7658 - val_loss: 4594898.0000 - val_mae: 1685.0621\n",
            "Epoch 148/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4899654.2917 - mae: 1511.2563 - val_loss: 5075181.0000 - val_mae: 1827.1893\n",
            "Epoch 149/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 5775171.9583 - mae: 1574.5667 - val_loss: 4155273.5000 - val_mae: 1610.7278\n",
            "Epoch 150/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4460127.6458 - mae: 1487.2431 - val_loss: 4955561.0000 - val_mae: 1704.7655\n",
            "Epoch 151/1000\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 8579639.0000 - mae: 1645.2190 - val_loss: 4406874.5000 - val_mae: 1635.7812\n",
            "Epoch 152/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 3765664.7917 - mae: 1408.2838 - val_loss: 6156829.5000 - val_mae: 1906.0332\n",
            "Epoch 153/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5219814.0625 - mae: 1591.0510 - val_loss: 5447042.0000 - val_mae: 1752.1729\n",
            "Epoch 154/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5428124.0625 - mae: 1504.6758 - val_loss: 4501088.0000 - val_mae: 1606.8826\n",
            "Epoch 155/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5724658.8958 - mae: 1489.2911 - val_loss: 5644078.5000 - val_mae: 1704.4359\n",
            "Epoch 156/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9904088.3333 - mae: 1656.9935 - val_loss: 4600017.5000 - val_mae: 1602.5112\n",
            "Epoch 157/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3779338.1667 - mae: 1387.9997 - val_loss: 4531533.0000 - val_mae: 1639.8295\n",
            "Epoch 158/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4682442.2500 - mae: 1494.6897 - val_loss: 6189517.0000 - val_mae: 1925.9985\n",
            "Epoch 159/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9510886.8750 - mae: 1780.5205 - val_loss: 5625560.5000 - val_mae: 1880.8256\n",
            "Epoch 160/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8100276.7917 - mae: 1810.8133 - val_loss: 4168606.7500 - val_mae: 1618.2421\n",
            "Epoch 161/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5011057.9792 - mae: 1588.2659 - val_loss: 4276291.0000 - val_mae: 1633.8912\n",
            "Epoch 162/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4158907.8542 - mae: 1481.8064 - val_loss: 4394617.5000 - val_mae: 1621.9556\n",
            "Epoch 163/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5787145.4375 - mae: 1427.9777 - val_loss: 4837217.5000 - val_mae: 1695.8442\n",
            "Epoch 164/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4172367.9375 - mae: 1386.1936 - val_loss: 4704033.5000 - val_mae: 1680.7776\n",
            "Epoch 165/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4014650.1458 - mae: 1457.5060 - val_loss: 4546063.0000 - val_mae: 1641.6487\n",
            "Epoch 166/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4484607.2292 - mae: 1441.8483 - val_loss: 4481960.5000 - val_mae: 1669.2183\n",
            "Epoch 167/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5644754.2083 - mae: 1406.5453 - val_loss: 4520787.5000 - val_mae: 1637.5720\n",
            "Epoch 168/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4726163.1458 - mae: 1425.3266 - val_loss: 4477522.5000 - val_mae: 1654.4360\n",
            "Epoch 169/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3842957.4583 - mae: 1399.4825 - val_loss: 4350466.0000 - val_mae: 1650.2802\n",
            "Epoch 170/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 6529496.0208 - mae: 1721.2482 - val_loss: 5550397.5000 - val_mae: 1866.7417\n",
            "Epoch 171/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6012228.6250 - mae: 1600.4491 - val_loss: 4968488.5000 - val_mae: 1734.6908\n",
            "Epoch 172/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 4623840.1875 - mae: 1524.8877 - val_loss: 7622053.5000 - val_mae: 2132.4727\n",
            "Epoch 173/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 5020027.3333 - mae: 1677.9858 - val_loss: 4438993.5000 - val_mae: 1583.5018\n",
            "Epoch 174/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6560623.9583 - mae: 1492.2071 - val_loss: 5887555.5000 - val_mae: 1939.4589\n",
            "Epoch 175/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4168319.8333 - mae: 1507.2581 - val_loss: 5298463.0000 - val_mae: 1741.9755\n",
            "Epoch 176/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5882118.6875 - mae: 1555.6676 - val_loss: 4753780.5000 - val_mae: 1657.6908\n",
            "Epoch 177/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4031397.6250 - mae: 1322.5911 - val_loss: 4535619.5000 - val_mae: 1588.4989\n",
            "Epoch 178/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4379032.0208 - mae: 1410.0367 - val_loss: 5893752.5000 - val_mae: 1937.6232\n",
            "Epoch 179/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6814927.9167 - mae: 1617.4875 - val_loss: 4242175.5000 - val_mae: 1573.0294\n",
            "Epoch 180/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4239498.6667 - mae: 1398.3232 - val_loss: 4675828.0000 - val_mae: 1663.6792\n",
            "Epoch 181/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4928928.8333 - mae: 1450.6402 - val_loss: 6014102.5000 - val_mae: 1956.9630\n",
            "Epoch 182/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4565978.5625 - mae: 1558.9752 - val_loss: 5123048.0000 - val_mae: 1766.5688\n",
            "Epoch 183/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 5915653.4583 - mae: 1466.0878 - val_loss: 4418640.5000 - val_mae: 1671.5583\n",
            "Epoch 184/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8743479.2083 - mae: 1625.1015 - val_loss: 5182166.0000 - val_mae: 1792.5123\n",
            "Epoch 185/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 9902097.3750 - mae: 1682.4029 - val_loss: 6379310.0000 - val_mae: 1937.6870\n",
            "Epoch 186/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6117427.6667 - mae: 1667.1260 - val_loss: 9276345.0000 - val_mae: 2574.0547\n",
            "Epoch 187/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8138825.6667 - mae: 1901.7826 - val_loss: 4307732.0000 - val_mae: 1596.2113\n",
            "Epoch 188/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6452742.7500 - mae: 1571.8437 - val_loss: 7173560.0000 - val_mae: 2106.1890\n",
            "Epoch 189/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6031407.9583 - mae: 1689.4026 - val_loss: 4307488.0000 - val_mae: 1549.7821\n",
            "Epoch 190/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6258704.5833 - mae: 1425.3613 - val_loss: 4286546.5000 - val_mae: 1603.4634\n",
            "Epoch 191/1000\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 6199728.2917 - mae: 1414.5206 - val_loss: 4914618.5000 - val_mae: 1705.6710\n",
            "Epoch 192/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4179192.7083 - mae: 1454.7696 - val_loss: 4992967.0000 - val_mae: 1653.5338\n",
            "Epoch 193/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3713016.8542 - mae: 1408.5691 - val_loss: 5900295.5000 - val_mae: 1901.1859\n",
            "Epoch 194/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4491891.1667 - mae: 1504.2694 - val_loss: 4186132.0000 - val_mae: 1576.5839\n",
            "Epoch 195/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3514131.3333 - mae: 1321.7622 - val_loss: 5649476.0000 - val_mae: 1939.7279\n",
            "Epoch 196/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5148815.2292 - mae: 1603.1505 - val_loss: 3764406.5000 - val_mae: 1506.1652\n",
            "Epoch 197/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4907916.1250 - mae: 1462.7643 - val_loss: 7047048.0000 - val_mae: 2112.3184\n",
            "Epoch 198/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6780258.6667 - mae: 1830.2245 - val_loss: 3988340.2500 - val_mae: 1544.3179\n",
            "Epoch 199/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3776724.2917 - mae: 1363.0293 - val_loss: 4481141.0000 - val_mae: 1555.7780\n",
            "Epoch 200/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7784938.0000 - mae: 1441.3417 - val_loss: 4657350.5000 - val_mae: 1667.2267\n",
            "Epoch 201/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3527057.4583 - mae: 1360.4606 - val_loss: 6034860.5000 - val_mae: 1956.7380\n",
            "Epoch 202/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8847366.6667 - mae: 1753.6090 - val_loss: 5780266.5000 - val_mae: 1873.2106\n",
            "Epoch 203/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6559901.2917 - mae: 1511.0063 - val_loss: 4262147.5000 - val_mae: 1568.0640\n",
            "Epoch 204/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3869288.6667 - mae: 1235.5888 - val_loss: 4308846.5000 - val_mae: 1615.8279\n",
            "Epoch 205/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6089183.6042 - mae: 1543.8317 - val_loss: 6660126.5000 - val_mae: 2068.7368\n",
            "Epoch 206/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8002518.8333 - mae: 1824.8633 - val_loss: 5712247.0000 - val_mae: 1851.4235\n",
            "Epoch 207/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4802865.8333 - mae: 1603.7457 - val_loss: 4652609.0000 - val_mae: 1625.8878\n",
            "Epoch 208/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4904757.5208 - mae: 1513.1057 - val_loss: 4420508.5000 - val_mae: 1676.3990\n",
            "Epoch 209/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5064257.4583 - mae: 1490.1746 - val_loss: 4732608.5000 - val_mae: 1614.4675\n",
            "Epoch 210/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4044148.7500 - mae: 1392.6456 - val_loss: 4913152.5000 - val_mae: 1644.2877\n",
            "Epoch 211/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4143810.1667 - mae: 1400.9278 - val_loss: 5420331.0000 - val_mae: 1776.5148\n",
            "Epoch 212/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4979604.0000 - mae: 1527.8404 - val_loss: 6150199.0000 - val_mae: 1921.5654\n",
            "Epoch 213/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4372549.7917 - mae: 1494.9152 - val_loss: 3972222.5000 - val_mae: 1501.2968\n",
            "Epoch 214/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4038765.2083 - mae: 1347.4764 - val_loss: 3903318.2500 - val_mae: 1491.9453\n",
            "Epoch 215/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7091515.9583 - mae: 1342.4153 - val_loss: 4119040.0000 - val_mae: 1575.4297\n",
            "Epoch 216/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3092626.7708 - mae: 1192.9505 - val_loss: 4293268.0000 - val_mae: 1575.3120\n",
            "Epoch 217/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4556202.3333 - mae: 1370.0974 - val_loss: 4766431.5000 - val_mae: 1664.1646\n",
            "Epoch 218/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3394276.9375 - mae: 1258.3146 - val_loss: 5055334.0000 - val_mae: 1702.0671\n",
            "Epoch 219/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5765696.4583 - mae: 1525.5766 - val_loss: 6695680.0000 - val_mae: 1945.2515\n",
            "Epoch 220/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5388919.5000 - mae: 1614.1843 - val_loss: 4972704.0000 - val_mae: 1712.9387\n",
            "Epoch 221/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5759403.6875 - mae: 1586.4960 - val_loss: 4709259.5000 - val_mae: 1663.2544\n",
            "Epoch 222/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3171562.8125 - mae: 1296.2998 - val_loss: 4692681.0000 - val_mae: 1695.1744\n",
            "Epoch 223/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5694718.5833 - mae: 1537.2660 - val_loss: 4149443.2500 - val_mae: 1558.1251\n",
            "Epoch 224/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3219810.2083 - mae: 1305.6709 - val_loss: 4592934.0000 - val_mae: 1669.6393\n",
            "Epoch 225/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5045003.6875 - mae: 1387.8258 - val_loss: 5002927.5000 - val_mae: 1701.8800\n",
            "Epoch 226/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6640075.7917 - mae: 1463.4713 - val_loss: 5383180.5000 - val_mae: 1789.1279\n",
            "Epoch 227/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4076698.0417 - mae: 1382.8684 - val_loss: 3831842.0000 - val_mae: 1504.7267\n",
            "Epoch 228/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3938060.2083 - mae: 1258.5388 - val_loss: 4642724.0000 - val_mae: 1639.7568\n",
            "Epoch 229/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4053589.9167 - mae: 1418.3073 - val_loss: 4818644.5000 - val_mae: 1698.7540\n",
            "Epoch 230/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7934655.3750 - mae: 1540.9567 - val_loss: 6362514.5000 - val_mae: 1989.8557\n",
            "Epoch 231/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5139370.8125 - mae: 1521.6589 - val_loss: 5361674.5000 - val_mae: 1794.9830\n",
            "Epoch 232/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4894190.4167 - mae: 1580.5517 - val_loss: 4921474.5000 - val_mae: 1684.1461\n",
            "Epoch 233/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5149671.1458 - mae: 1293.4471 - val_loss: 3933135.5000 - val_mae: 1518.6477\n",
            "Epoch 234/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4057419.7812 - mae: 1231.0870 - val_loss: 3828805.5000 - val_mae: 1508.2810\n",
            "Epoch 235/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4098066.6562 - mae: 1408.6884 - val_loss: 4829295.5000 - val_mae: 1676.2693\n",
            "Epoch 236/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5516169.1667 - mae: 1479.7369 - val_loss: 7545413.5000 - val_mae: 2257.7080\n",
            "Epoch 237/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8483656.2500 - mae: 1610.3032 - val_loss: 5494019.5000 - val_mae: 1835.9375\n",
            "Epoch 238/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6759750.1875 - mae: 1489.6276 - val_loss: 4478152.5000 - val_mae: 1639.1981\n",
            "Epoch 239/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3714314.9375 - mae: 1311.8844 - val_loss: 4747268.0000 - val_mae: 1593.7540\n",
            "Epoch 240/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3249089.5833 - mae: 1277.9070 - val_loss: 5686856.5000 - val_mae: 1666.2717\n",
            "Epoch 241/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5152333.6875 - mae: 1598.8155 - val_loss: 6902701.0000 - val_mae: 2122.2720\n",
            "Epoch 242/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5448244.3542 - mae: 1700.7378 - val_loss: 5630346.5000 - val_mae: 1818.3121\n",
            "Epoch 243/1000\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 4626964.9375 - mae: 1533.4282 - val_loss: 6085046.0000 - val_mae: 1935.3779\n",
            "Epoch 244/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4147084.3333 - mae: 1496.9011 - val_loss: 4227460.5000 - val_mae: 1587.7019\n",
            "Epoch 245/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2983952.5625 - mae: 1246.1628 - val_loss: 4627565.0000 - val_mae: 1650.1954\n",
            "Epoch 246/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5635332.7500 - mae: 1484.4547 - val_loss: 5320651.5000 - val_mae: 1787.3362\n",
            "Epoch 247/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4879003.3750 - mae: 1598.8866 - val_loss: 5496932.5000 - val_mae: 1849.9186\n",
            "Epoch 248/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5444832.3125 - mae: 1422.5687 - val_loss: 3660696.0000 - val_mae: 1444.7706\n",
            "Epoch 249/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5981021.6667 - mae: 1296.2517 - val_loss: 4778002.0000 - val_mae: 1686.9050\n",
            "Epoch 250/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4787032.5625 - mae: 1353.2281 - val_loss: 4119913.5000 - val_mae: 1556.7034\n",
            "Epoch 251/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8467613.4167 - mae: 1577.4582 - val_loss: 7057991.0000 - val_mae: 2205.3865\n",
            "Epoch 252/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5075258.7708 - mae: 1609.1787 - val_loss: 4007367.5000 - val_mae: 1533.0782\n",
            "Epoch 253/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5284174.9583 - mae: 1360.8516 - val_loss: 4479476.5000 - val_mae: 1544.8013\n",
            "Epoch 254/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2866809.2708 - mae: 1181.9148 - val_loss: 5025247.0000 - val_mae: 1727.5731\n",
            "Epoch 255/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5298170.2083 - mae: 1364.4422 - val_loss: 3965676.0000 - val_mae: 1505.3143\n",
            "Epoch 256/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3294911.8125 - mae: 1205.8023 - val_loss: 4296164.0000 - val_mae: 1573.8844\n",
            "Epoch 257/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4985584.2083 - mae: 1385.0961 - val_loss: 4603445.5000 - val_mae: 1643.1829\n",
            "Epoch 258/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3352592.2083 - mae: 1189.0372 - val_loss: 4059865.5000 - val_mae: 1553.4989\n",
            "Epoch 259/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3645465.5833 - mae: 1216.2094 - val_loss: 4146124.5000 - val_mae: 1539.0925\n",
            "Epoch 260/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3526069.5312 - mae: 1167.4509 - val_loss: 3895949.2500 - val_mae: 1482.6855\n",
            "Epoch 261/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4062539.5208 - mae: 1255.5243 - val_loss: 5554516.0000 - val_mae: 1758.1359\n",
            "Epoch 262/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4248636.5417 - mae: 1399.9717 - val_loss: 5280382.5000 - val_mae: 1802.0568\n",
            "Epoch 263/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4426390.5000 - mae: 1386.6541 - val_loss: 3975310.0000 - val_mae: 1516.2463\n",
            "Epoch 264/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2995269.6146 - mae: 1174.4675 - val_loss: 4231905.5000 - val_mae: 1543.3351\n",
            "Epoch 265/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3501977.1042 - mae: 1213.1892 - val_loss: 4781872.5000 - val_mae: 1694.4597\n",
            "Epoch 266/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7430480.1250 - mae: 1398.1671 - val_loss: 5622739.5000 - val_mae: 1751.8787\n",
            "Epoch 267/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4327557.7083 - mae: 1332.8264 - val_loss: 4067817.0000 - val_mae: 1541.0946\n",
            "Epoch 268/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3725381.6875 - mae: 1270.3165 - val_loss: 4218151.5000 - val_mae: 1529.6356\n",
            "Epoch 269/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3100861.9375 - mae: 1208.5794 - val_loss: 4083910.2500 - val_mae: 1481.0203\n",
            "Epoch 270/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7082739.5000 - mae: 1337.0860 - val_loss: 4279354.0000 - val_mae: 1507.1891\n",
            "Epoch 271/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4987139.3646 - mae: 1196.2431 - val_loss: 4212293.5000 - val_mae: 1563.0056\n",
            "Epoch 272/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3842634.0417 - mae: 1296.8738 - val_loss: 4578935.5000 - val_mae: 1650.7748\n",
            "Epoch 273/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3203726.1875 - mae: 1321.3094 - val_loss: 4074987.0000 - val_mae: 1492.6246\n",
            "Epoch 274/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 3602929.3229 - mae: 1132.2533 - val_loss: 3834613.0000 - val_mae: 1471.4146\n",
            "Epoch 275/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2610954.8021 - mae: 1160.6684 - val_loss: 4080805.7500 - val_mae: 1504.6119\n",
            "Epoch 276/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4859048.6875 - mae: 1283.1636 - val_loss: 5048522.5000 - val_mae: 1752.9639\n",
            "Epoch 277/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3362017.2708 - mae: 1231.4925 - val_loss: 4156593.5000 - val_mae: 1543.4653\n",
            "Epoch 278/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4930534.4583 - mae: 1274.5332 - val_loss: 5296766.0000 - val_mae: 1704.5658\n",
            "Epoch 279/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4998385.3333 - mae: 1271.0629 - val_loss: 4126369.2500 - val_mae: 1544.0825\n",
            "Epoch 280/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6621722.0833 - mae: 1229.5466 - val_loss: 4448103.0000 - val_mae: 1602.4609\n",
            "Epoch 281/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4884836.0625 - mae: 1296.6074 - val_loss: 3890751.2500 - val_mae: 1495.7926\n",
            "Epoch 282/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4364849.0000 - mae: 1227.1490 - val_loss: 3964793.7500 - val_mae: 1488.7919\n",
            "Epoch 283/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2743407.4375 - mae: 1203.1572 - val_loss: 4000363.7500 - val_mae: 1456.8159\n",
            "Epoch 284/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5656342.9167 - mae: 1372.7753 - val_loss: 4369545.0000 - val_mae: 1586.2582\n",
            "Epoch 285/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7144195.9167 - mae: 1393.7969 - val_loss: 5668960.0000 - val_mae: 1882.8342\n",
            "Epoch 286/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3174032.1250 - mae: 1278.5305 - val_loss: 4205489.0000 - val_mae: 1567.1882\n",
            "Epoch 287/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7180844.2500 - mae: 1348.2271 - val_loss: 4022997.7500 - val_mae: 1510.6343\n",
            "Epoch 288/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2420725.2917 - mae: 1077.2040 - val_loss: 3804046.7500 - val_mae: 1447.8694\n",
            "Epoch 289/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4804437.7917 - mae: 1265.4343 - val_loss: 3957016.5000 - val_mae: 1472.5515\n",
            "Epoch 290/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6188669.2292 - mae: 1542.8266 - val_loss: 6089073.0000 - val_mae: 1880.6619\n",
            "Epoch 291/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6528327.7083 - mae: 1449.6370 - val_loss: 4640520.0000 - val_mae: 1640.9978\n",
            "Epoch 292/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3311279.9167 - mae: 1191.6622 - val_loss: 6398298.5000 - val_mae: 2008.7186\n",
            "Epoch 293/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8435959.9583 - mae: 1821.3165 - val_loss: 4845745.0000 - val_mae: 1644.5044\n",
            "Epoch 294/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4323449.2917 - mae: 1415.6005 - val_loss: 4829876.0000 - val_mae: 1631.1483\n",
            "Epoch 295/1000\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 4659847.6250 - mae: 1229.8719 - val_loss: 3871108.0000 - val_mae: 1503.2999\n",
            "Epoch 296/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4453479.0104 - mae: 1148.0336 - val_loss: 4030984.2500 - val_mae: 1478.3370\n",
            "Epoch 297/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2434803.8125 - mae: 1098.3264 - val_loss: 3680524.5000 - val_mae: 1422.5916\n",
            "Epoch 298/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3999010.2812 - mae: 1144.8521 - val_loss: 4007232.2500 - val_mae: 1494.6002\n",
            "Epoch 299/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3398756.1875 - mae: 1246.0345 - val_loss: 4170050.5000 - val_mae: 1497.8422\n",
            "Epoch 300/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3473631.0000 - mae: 1205.9848 - val_loss: 4426703.0000 - val_mae: 1580.2986\n",
            "Epoch 301/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3829459.4583 - mae: 1169.3897 - val_loss: 4463910.0000 - val_mae: 1553.0730\n",
            "Epoch 302/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2588326.9896 - mae: 1086.1559 - val_loss: 4596381.0000 - val_mae: 1663.1893\n",
            "Epoch 303/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4041895.5833 - mae: 1195.9871 - val_loss: 4684337.0000 - val_mae: 1646.8806\n",
            "Epoch 304/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4629219.3125 - mae: 1249.7480 - val_loss: 3933815.5000 - val_mae: 1498.9552\n",
            "Epoch 305/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2951650.2708 - mae: 1147.5841 - val_loss: 3829548.7500 - val_mae: 1462.1467\n",
            "Epoch 306/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2536356.7917 - mae: 1074.8532 - val_loss: 4301242.0000 - val_mae: 1521.5856\n",
            "Epoch 307/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2496780.0104 - mae: 1084.5411 - val_loss: 4886375.0000 - val_mae: 1708.2068\n",
            "Epoch 308/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4808676.8125 - mae: 1288.1069 - val_loss: 4506857.0000 - val_mae: 1578.9592\n",
            "Epoch 309/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2764196.4271 - mae: 1077.0386 - val_loss: 4384276.5000 - val_mae: 1573.9575\n",
            "Epoch 310/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4252768.6042 - mae: 1239.3218 - val_loss: 5386579.0000 - val_mae: 1790.2568\n",
            "Epoch 311/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3010382.9792 - mae: 1219.9246 - val_loss: 3712101.0000 - val_mae: 1432.2904\n",
            "Epoch 312/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 2037631.9792 - mae: 1015.1608 - val_loss: 3734995.2500 - val_mae: 1450.5338\n",
            "Epoch 313/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5075621.0833 - mae: 1211.1368 - val_loss: 4705477.0000 - val_mae: 1635.7574\n",
            "Epoch 314/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3942398.7708 - mae: 1125.1917 - val_loss: 4003734.2500 - val_mae: 1507.8960\n",
            "Epoch 315/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3221763.4375 - mae: 1193.8704 - val_loss: 5569002.5000 - val_mae: 1771.7933\n",
            "Epoch 316/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5185482.5417 - mae: 1301.3770 - val_loss: 4959590.0000 - val_mae: 1727.7963\n",
            "Epoch 317/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3759693.7708 - mae: 1153.1273 - val_loss: 3813672.7500 - val_mae: 1413.9427\n",
            "Epoch 318/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2764504.3646 - mae: 1078.5818 - val_loss: 4034043.5000 - val_mae: 1468.2769\n",
            "Epoch 319/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3160255.7708 - mae: 1262.3006 - val_loss: 3989978.2500 - val_mae: 1439.7653\n",
            "Epoch 320/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5180165.8229 - mae: 1203.5957 - val_loss: 4106484.2500 - val_mae: 1497.3785\n",
            "Epoch 321/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4637085.0938 - mae: 1221.8941 - val_loss: 5032190.0000 - val_mae: 1626.5999\n",
            "Epoch 322/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3458883.2083 - mae: 1205.6514 - val_loss: 4612763.0000 - val_mae: 1531.7870\n",
            "Epoch 323/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4189522.9896 - mae: 1217.0131 - val_loss: 3940516.0000 - val_mae: 1429.4207\n",
            "Epoch 324/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3690823.3229 - mae: 1070.4857 - val_loss: 3701720.5000 - val_mae: 1398.1943\n",
            "Epoch 325/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2575687.9167 - mae: 1029.9215 - val_loss: 4119477.2500 - val_mae: 1502.5057\n",
            "Epoch 326/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3147900.0938 - mae: 1176.7959 - val_loss: 4148588.5000 - val_mae: 1471.2318\n",
            "Epoch 327/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3310111.0521 - mae: 1124.2997 - val_loss: 4189523.5000 - val_mae: 1541.4016\n",
            "Epoch 328/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4022531.0104 - mae: 1216.3332 - val_loss: 6672880.5000 - val_mae: 2104.9119\n",
            "Epoch 329/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4314723.7083 - mae: 1422.7093 - val_loss: 4014120.2500 - val_mae: 1483.8889\n",
            "Epoch 330/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4244094.0417 - mae: 1130.0815 - val_loss: 4023018.2500 - val_mae: 1489.1198\n",
            "Epoch 331/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2700556.5104 - mae: 1159.8702 - val_loss: 5053642.5000 - val_mae: 1649.9318\n",
            "Epoch 332/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4615392.9167 - mae: 1299.7305 - val_loss: 5387371.5000 - val_mae: 1694.6573\n",
            "Epoch 333/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5575831.6667 - mae: 1349.7481 - val_loss: 5000760.0000 - val_mae: 1628.1189\n",
            "Epoch 334/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3123169.7708 - mae: 1157.5358 - val_loss: 4901061.0000 - val_mae: 1615.4758\n",
            "Epoch 335/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3345593.3958 - mae: 1152.0999 - val_loss: 5466296.0000 - val_mae: 1775.7766\n",
            "Epoch 336/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6041586.5104 - mae: 1422.2443 - val_loss: 4979320.0000 - val_mae: 1696.7603\n",
            "Epoch 337/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3488014.3333 - mae: 1332.4009 - val_loss: 5510187.5000 - val_mae: 1825.1051\n",
            "Epoch 338/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3707301.0833 - mae: 1271.8446 - val_loss: 4797244.0000 - val_mae: 1645.3298\n",
            "Epoch 339/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3591297.1667 - mae: 1309.5320 - val_loss: 5911345.5000 - val_mae: 1948.0957\n",
            "Epoch 340/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3609768.1667 - mae: 1323.2972 - val_loss: 5832517.0000 - val_mae: 1946.8533\n",
            "Epoch 341/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5060608.2083 - mae: 1539.3505 - val_loss: 4851636.0000 - val_mae: 1659.8562\n",
            "Epoch 342/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3839717.6771 - mae: 1185.8757 - val_loss: 4167159.7500 - val_mae: 1526.5244\n",
            "Epoch 343/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4444829.4167 - mae: 1197.0137 - val_loss: 3832906.7500 - val_mae: 1434.0259\n",
            "Epoch 344/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4979007.3125 - mae: 1183.6886 - val_loss: 4742017.5000 - val_mae: 1551.8905\n",
            "Epoch 345/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2505504.3750 - mae: 1134.8057 - val_loss: 5770000.5000 - val_mae: 1755.6740\n",
            "Epoch 346/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4494198.7500 - mae: 1443.4483 - val_loss: 8130440.0000 - val_mae: 2363.0088\n",
            "Epoch 347/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4865025.8333 - mae: 1716.6829 - val_loss: 7676148.0000 - val_mae: 2124.8381\n",
            "Epoch 348/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5056605.0208 - mae: 1581.5697 - val_loss: 10290914.0000 - val_mae: 2641.1250\n",
            "Epoch 349/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4833653.0417 - mae: 1753.4964 - val_loss: 6734223.0000 - val_mae: 2057.8411\n",
            "Epoch 350/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4778068.3958 - mae: 1490.9278 - val_loss: 4262734.5000 - val_mae: 1537.8577\n",
            "Epoch 351/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2497911.4167 - mae: 1071.1336 - val_loss: 3632029.5000 - val_mae: 1390.3483\n",
            "Epoch 352/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3064644.5521 - mae: 988.0418 - val_loss: 4023993.7500 - val_mae: 1430.9901\n",
            "Epoch 353/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3637185.8333 - mae: 959.4352 - val_loss: 4402839.5000 - val_mae: 1570.9948\n",
            "Epoch 354/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2560048.9688 - mae: 1066.8642 - val_loss: 3958527.2500 - val_mae: 1433.2402\n",
            "Epoch 355/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2583339.5625 - mae: 1099.1144 - val_loss: 3858509.7500 - val_mae: 1484.9323\n",
            "Epoch 356/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6230048.5625 - mae: 1207.0863 - val_loss: 4578307.0000 - val_mae: 1520.5735\n",
            "Epoch 357/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3374991.1979 - mae: 1087.0262 - val_loss: 4589787.5000 - val_mae: 1584.1750\n",
            "Epoch 358/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2568299.7604 - mae: 1164.5563 - val_loss: 6204752.5000 - val_mae: 1978.5569\n",
            "Epoch 359/1000\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 4419884.0208 - mae: 1677.5715 - val_loss: 4358998.5000 - val_mae: 1570.1130\n",
            "Epoch 360/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7353391.1667 - mae: 1476.0918 - val_loss: 4288173.0000 - val_mae: 1501.0471\n",
            "Epoch 361/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4130009.6875 - mae: 1451.6661 - val_loss: 5246021.5000 - val_mae: 1733.2102\n",
            "Epoch 362/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6605890.2500 - mae: 1353.5744 - val_loss: 4482054.5000 - val_mae: 1606.6422\n",
            "Epoch 363/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3343319.5104 - mae: 1107.2419 - val_loss: 3500336.0000 - val_mae: 1367.8505\n",
            "Epoch 364/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2989167.1458 - mae: 1141.0979 - val_loss: 3793001.7500 - val_mae: 1414.1259\n",
            "Epoch 365/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3125862.9375 - mae: 1255.9271 - val_loss: 4151662.5000 - val_mae: 1537.2839\n",
            "Epoch 366/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 3635837.3229 - mae: 1238.0402 - val_loss: 3957863.5000 - val_mae: 1428.5950\n",
            "Epoch 367/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3549250.7188 - mae: 1119.8296 - val_loss: 3812391.2500 - val_mae: 1439.0680\n",
            "Epoch 368/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5501261.1667 - mae: 1306.4256 - val_loss: 3866000.2500 - val_mae: 1439.3727\n",
            "Epoch 369/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2207228.2292 - mae: 1030.5932 - val_loss: 4394787.0000 - val_mae: 1636.7644\n",
            "Epoch 370/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3526953.0000 - mae: 1229.2270 - val_loss: 4161956.0000 - val_mae: 1468.5226\n",
            "Epoch 371/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2762918.8438 - mae: 1045.9909 - val_loss: 4207450.5000 - val_mae: 1482.7883\n",
            "Epoch 372/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3977034.0000 - mae: 1155.4493 - val_loss: 3920477.5000 - val_mae: 1465.5659\n",
            "Epoch 373/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2142064.8646 - mae: 1038.9146 - val_loss: 4166153.0000 - val_mae: 1482.6045\n",
            "Epoch 374/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2467805.9167 - mae: 1056.5982 - val_loss: 4888292.0000 - val_mae: 1620.0878\n",
            "Epoch 375/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2777244.7396 - mae: 1089.9906 - val_loss: 5765202.0000 - val_mae: 1852.4148\n",
            "Epoch 376/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3312857.0208 - mae: 1364.4100 - val_loss: 4784748.0000 - val_mae: 1717.1637\n",
            "Epoch 377/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4067353.4688 - mae: 1304.0838 - val_loss: 4750717.0000 - val_mae: 1611.4277\n",
            "Epoch 378/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2676713.8542 - mae: 1129.8082 - val_loss: 4197798.5000 - val_mae: 1484.8536\n",
            "Epoch 379/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3484076.2604 - mae: 1069.2706 - val_loss: 4259791.0000 - val_mae: 1518.3291\n",
            "Epoch 380/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2333356.2396 - mae: 1057.5135 - val_loss: 5116705.0000 - val_mae: 1587.5317\n",
            "Epoch 381/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5340518.1250 - mae: 1275.0247 - val_loss: 4762710.0000 - val_mae: 1655.2703\n",
            "Epoch 382/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2148523.7396 - mae: 1013.2526 - val_loss: 4708607.0000 - val_mae: 1571.6255\n",
            "Epoch 383/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2788676.3958 - mae: 1021.1262 - val_loss: 4786626.0000 - val_mae: 1484.9584\n",
            "Epoch 384/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2049547.5208 - mae: 985.4707 - val_loss: 4084878.5000 - val_mae: 1454.9280\n",
            "Epoch 385/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4306814.9792 - mae: 1092.2745 - val_loss: 7049959.0000 - val_mae: 1984.2279\n",
            "Epoch 386/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 7806434.7083 - mae: 1516.0978 - val_loss: 5575569.0000 - val_mae: 1721.1434\n",
            "Epoch 387/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6821596.9167 - mae: 1516.2311 - val_loss: 8836021.0000 - val_mae: 2194.5669\n",
            "Epoch 388/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 11466206.1667 - mae: 2163.7906 - val_loss: 5987763.0000 - val_mae: 1838.0189\n",
            "Epoch 389/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6563698.4375 - mae: 1601.9417 - val_loss: 6390014.5000 - val_mae: 1831.6405\n",
            "Epoch 390/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 5316531.5208 - mae: 1420.4989 - val_loss: 4053676.0000 - val_mae: 1533.0248\n",
            "Epoch 391/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2746739.6458 - mae: 1094.9908 - val_loss: 3892207.7500 - val_mae: 1444.3152\n",
            "Epoch 392/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4945181.8750 - mae: 1154.5241 - val_loss: 4122115.0000 - val_mae: 1469.9910\n",
            "Epoch 393/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3962653.5104 - mae: 1073.4526 - val_loss: 5291802.5000 - val_mae: 1783.3529\n",
            "Epoch 394/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4534072.0417 - mae: 1352.2423 - val_loss: 7857232.0000 - val_mae: 2301.6816\n",
            "Epoch 395/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4143163.6458 - mae: 1507.7877 - val_loss: 4447851.0000 - val_mae: 1581.6228\n",
            "Epoch 396/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 3599934.4167 - mae: 1286.1785 - val_loss: 4076084.5000 - val_mae: 1476.1714\n",
            "Epoch 397/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3381623.2917 - mae: 1119.9201 - val_loss: 4288095.5000 - val_mae: 1485.6426\n",
            "Epoch 398/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3511017.0938 - mae: 1149.7766 - val_loss: 4556352.0000 - val_mae: 1548.0199\n",
            "Epoch 399/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3669034.9792 - mae: 1197.3035 - val_loss: 4701913.0000 - val_mae: 1564.7043\n",
            "Epoch 400/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4165378.7500 - mae: 1174.7163 - val_loss: 5445480.0000 - val_mae: 1688.7018\n",
            "Epoch 401/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4854093.1667 - mae: 1137.9351 - val_loss: 4623847.0000 - val_mae: 1565.1072\n",
            "Epoch 402/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3127913.0000 - mae: 1196.6158 - val_loss: 7069851.5000 - val_mae: 2125.0750\n",
            "Epoch 403/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4253394.6875 - mae: 1380.5713 - val_loss: 4229975.5000 - val_mae: 1454.4410\n",
            "Epoch 404/1000\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 2924915.9896 - mae: 1005.8186 - val_loss: 4269959.5000 - val_mae: 1463.3119\n",
            "Epoch 405/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4404797.8021 - mae: 1072.5220 - val_loss: 4040612.5000 - val_mae: 1477.9113\n",
            "Epoch 406/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3680357.0938 - mae: 1026.6485 - val_loss: 4620466.5000 - val_mae: 1545.5294\n",
            "Epoch 407/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3740038.8646 - mae: 1020.1427 - val_loss: 4535703.5000 - val_mae: 1529.6992\n",
            "Epoch 408/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2149923.2917 - mae: 983.1668 - val_loss: 4765263.0000 - val_mae: 1520.2627\n",
            "Epoch 409/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2847771.3229 - mae: 963.8763 - val_loss: 4095365.2500 - val_mae: 1433.5585\n",
            "Epoch 410/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2144016.2188 - mae: 949.6754 - val_loss: 4452570.5000 - val_mae: 1478.2429\n",
            "Epoch 411/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2758432.6354 - mae: 998.5035 - val_loss: 5062975.5000 - val_mae: 1680.8129\n",
            "Epoch 412/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1988333.5208 - mae: 915.2582 - val_loss: 4349840.5000 - val_mae: 1438.5908\n",
            "Epoch 413/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2252043.8646 - mae: 907.1496 - val_loss: 4219199.5000 - val_mae: 1446.6453\n",
            "Epoch 414/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1951743.6771 - mae: 936.4454 - val_loss: 4529501.0000 - val_mae: 1454.4388\n",
            "Epoch 415/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2540722.0938 - mae: 912.7236 - val_loss: 4422394.0000 - val_mae: 1516.4709\n",
            "Epoch 416/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5595424.9583 - mae: 1076.4286 - val_loss: 4899880.5000 - val_mae: 1557.2722\n",
            "Epoch 417/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1984071.9062 - mae: 936.4286 - val_loss: 5066670.5000 - val_mae: 1507.3474\n",
            "Epoch 418/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1910570.2604 - mae: 940.7026 - val_loss: 5899627.5000 - val_mae: 1867.1925\n",
            "Epoch 419/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3107775.5833 - mae: 1330.9680 - val_loss: 4638736.5000 - val_mae: 1517.5784\n",
            "Epoch 420/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2025114.8854 - mae: 1005.8763 - val_loss: 4154426.7500 - val_mae: 1456.2968\n",
            "Epoch 421/1000\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 2561669.4792 - mae: 1084.9166 - val_loss: 4368635.5000 - val_mae: 1408.0103\n",
            "Epoch 422/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3962379.8646 - mae: 1013.0943 - val_loss: 4736219.5000 - val_mae: 1556.5197\n",
            "Epoch 423/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4126336.0208 - mae: 1009.5704 - val_loss: 4338359.5000 - val_mae: 1492.4447\n",
            "Epoch 424/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 5568023.5625 - mae: 1094.5994 - val_loss: 4868772.0000 - val_mae: 1581.8783\n",
            "Epoch 425/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3318111.9896 - mae: 1027.4923 - val_loss: 4226132.0000 - val_mae: 1493.7766\n",
            "Epoch 426/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2053128.7083 - mae: 956.7817 - val_loss: 4744982.5000 - val_mae: 1510.8561\n",
            "Epoch 427/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1707151.0729 - mae: 923.7736 - val_loss: 5870917.5000 - val_mae: 1903.7443\n",
            "Epoch 428/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2814227.9167 - mae: 1267.3240 - val_loss: 4883677.0000 - val_mae: 1584.3945\n",
            "Epoch 429/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2191046.2917 - mae: 1006.5318 - val_loss: 4511159.0000 - val_mae: 1491.0681\n",
            "Epoch 430/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3291054.2917 - mae: 939.3233 - val_loss: 4428620.0000 - val_mae: 1548.4612\n",
            "Epoch 431/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2225055.7396 - mae: 1007.2094 - val_loss: 4513743.0000 - val_mae: 1480.4857\n",
            "Epoch 432/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2121371.7188 - mae: 907.9041 - val_loss: 5294917.0000 - val_mae: 1730.9182\n",
            "Epoch 433/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4453897.3958 - mae: 1158.0623 - val_loss: 4230448.0000 - val_mae: 1406.2144\n",
            "Epoch 434/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1833644.5208 - mae: 951.1642 - val_loss: 4217450.5000 - val_mae: 1397.4030\n",
            "Epoch 435/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2121853.2188 - mae: 850.5320 - val_loss: 4436820.5000 - val_mae: 1461.2380\n",
            "Epoch 436/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1820262.4896 - mae: 961.2475 - val_loss: 5001939.5000 - val_mae: 1602.4436\n",
            "Epoch 437/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3162283.9062 - mae: 1248.1121 - val_loss: 4712128.5000 - val_mae: 1525.2363\n",
            "Epoch 438/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2232393.9375 - mae: 1099.4652 - val_loss: 4774910.5000 - val_mae: 1492.6057\n",
            "Epoch 439/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2871219.2083 - mae: 1027.5048 - val_loss: 4235915.0000 - val_mae: 1477.2137\n",
            "Epoch 440/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3990385.6146 - mae: 939.9823 - val_loss: 4549689.5000 - val_mae: 1503.9884\n",
            "Epoch 441/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3768145.0000 - mae: 1137.6451 - val_loss: 5906835.5000 - val_mae: 1732.1528\n",
            "Epoch 442/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2407847.1771 - mae: 1089.6027 - val_loss: 4765844.0000 - val_mae: 1580.5109\n",
            "Epoch 443/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3417980.3229 - mae: 1251.8279 - val_loss: 4318952.0000 - val_mae: 1498.0358\n",
            "Epoch 444/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2555486.2812 - mae: 1043.3346 - val_loss: 4279140.5000 - val_mae: 1472.3284\n",
            "Epoch 445/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2458529.8750 - mae: 1077.7703 - val_loss: 5174860.0000 - val_mae: 1630.8577\n",
            "Epoch 446/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2890433.9062 - mae: 1096.6311 - val_loss: 4754649.5000 - val_mae: 1475.7681\n",
            "Epoch 447/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3728509.3333 - mae: 1078.9339 - val_loss: 4905123.0000 - val_mae: 1647.2753\n",
            "Epoch 448/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2486830.6250 - mae: 1053.7633 - val_loss: 4976624.5000 - val_mae: 1579.5135\n",
            "Epoch 449/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4129170.9583 - mae: 1110.3031 - val_loss: 4547229.0000 - val_mae: 1478.8441\n",
            "Epoch 450/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4568024.8438 - mae: 1320.6338 - val_loss: 4415942.5000 - val_mae: 1502.7755\n",
            "Epoch 451/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4579122.2500 - mae: 1180.3252 - val_loss: 4980687.5000 - val_mae: 1533.3826\n",
            "Epoch 452/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3088902.6771 - mae: 1092.5630 - val_loss: 4725288.5000 - val_mae: 1527.3806\n",
            "Epoch 453/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2436006.4688 - mae: 965.4484 - val_loss: 4901634.0000 - val_mae: 1505.1517\n",
            "Epoch 454/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2744474.2396 - mae: 1021.0627 - val_loss: 4751247.5000 - val_mae: 1523.8555\n",
            "Epoch 455/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3679471.4792 - mae: 1088.1677 - val_loss: 6296033.0000 - val_mae: 1738.1027\n",
            "Epoch 456/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4565603.7917 - mae: 1434.2877 - val_loss: 6984269.0000 - val_mae: 1826.1510\n",
            "Epoch 457/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3545917.3125 - mae: 1230.0739 - val_loss: 4592515.5000 - val_mae: 1524.2467\n",
            "Epoch 458/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1745790.2917 - mae: 919.0970 - val_loss: 5361194.5000 - val_mae: 1674.3331\n",
            "Epoch 459/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2307577.9271 - mae: 1072.1077 - val_loss: 4854432.0000 - val_mae: 1545.7538\n",
            "Epoch 460/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2218233.1354 - mae: 1037.8456 - val_loss: 6060927.5000 - val_mae: 1648.8976\n",
            "Epoch 461/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3491886.2604 - mae: 1132.3277 - val_loss: 5123625.5000 - val_mae: 1487.7024\n",
            "Epoch 462/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1927487.3021 - mae: 956.9223 - val_loss: 5517094.5000 - val_mae: 1620.5106\n",
            "Epoch 463/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2289460.0312 - mae: 1018.7524 - val_loss: 4975360.5000 - val_mae: 1498.9075\n",
            "Epoch 464/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1681975.6771 - mae: 901.4613 - val_loss: 4671762.0000 - val_mae: 1476.9292\n",
            "Epoch 465/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1627868.1354 - mae: 864.1060 - val_loss: 4954221.0000 - val_mae: 1496.7365\n",
            "Epoch 466/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2755396.4062 - mae: 940.9329 - val_loss: 5628105.5000 - val_mae: 1714.4532\n",
            "Epoch 467/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2695312.5104 - mae: 1194.0851 - val_loss: 7112205.5000 - val_mae: 1912.1558\n",
            "Epoch 468/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2665712.0625 - mae: 1227.4240 - val_loss: 6035544.5000 - val_mae: 1779.9921\n",
            "Epoch 469/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3993170.6667 - mae: 1321.9003 - val_loss: 5141017.0000 - val_mae: 1712.4884\n",
            "Epoch 470/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3422381.1875 - mae: 1219.7006 - val_loss: 5923838.5000 - val_mae: 1710.1283\n",
            "Epoch 471/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4334965.4583 - mae: 1576.6572 - val_loss: 4593845.5000 - val_mae: 1521.0905\n",
            "Epoch 472/1000\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 3592404.4688 - mae: 1206.3513 - val_loss: 6306750.0000 - val_mae: 1895.3422\n",
            "Epoch 473/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4562707.3333 - mae: 1315.1762 - val_loss: 4786484.0000 - val_mae: 1587.4924\n",
            "Epoch 474/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3520001.6042 - mae: 1052.6222 - val_loss: 4771244.0000 - val_mae: 1534.2365\n",
            "Epoch 475/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2220540.0521 - mae: 911.2698 - val_loss: 4726902.0000 - val_mae: 1549.7662\n",
            "Epoch 476/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2672486.2083 - mae: 963.3300 - val_loss: 5702476.0000 - val_mae: 1678.7574\n",
            "Epoch 477/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2432347.2396 - mae: 1017.9751 - val_loss: 4888471.5000 - val_mae: 1459.7186\n",
            "Epoch 478/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2189495.3021 - mae: 925.7371 - val_loss: 6023406.0000 - val_mae: 1754.3671\n",
            "Epoch 479/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3136921.4792 - mae: 1110.5856 - val_loss: 5535485.0000 - val_mae: 1739.9722\n",
            "Epoch 480/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2868458.0208 - mae: 1031.3877 - val_loss: 4798049.5000 - val_mae: 1503.1603\n",
            "Epoch 481/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4466050.8542 - mae: 918.4078 - val_loss: 4635242.0000 - val_mae: 1451.9702\n",
            "Epoch 482/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2845631.8021 - mae: 870.2375 - val_loss: 5725519.5000 - val_mae: 1749.0654\n",
            "Epoch 483/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1671710.8646 - mae: 962.9676 - val_loss: 5576695.0000 - val_mae: 1528.8314\n",
            "Epoch 484/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3035786.5625 - mae: 910.0177 - val_loss: 4406515.5000 - val_mae: 1415.2177\n",
            "Epoch 485/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3436335.1250 - mae: 927.0785 - val_loss: 4833639.5000 - val_mae: 1567.8468\n",
            "Epoch 486/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1961349.7812 - mae: 915.5122 - val_loss: 7148882.0000 - val_mae: 1845.1536\n",
            "Epoch 487/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3717971.2812 - mae: 1215.7339 - val_loss: 5482263.5000 - val_mae: 1756.1825\n",
            "Epoch 488/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2547976.5625 - mae: 1198.1188 - val_loss: 5943291.0000 - val_mae: 1562.8757\n",
            "Epoch 489/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1908233.4479 - mae: 1013.6786 - val_loss: 5366754.0000 - val_mae: 1543.3661\n",
            "Epoch 490/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2420331.1250 - mae: 916.4033 - val_loss: 4750299.5000 - val_mae: 1416.4553\n",
            "Epoch 491/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1352148.5990 - mae: 806.1661 - val_loss: 5495933.0000 - val_mae: 1551.2206\n",
            "Epoch 492/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1379426.2083 - mae: 849.8832 - val_loss: 4994835.5000 - val_mae: 1451.7158\n",
            "Epoch 493/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3487614.0417 - mae: 986.6865 - val_loss: 4193289.0000 - val_mae: 1441.7162\n",
            "Epoch 494/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1812806.2917 - mae: 816.2690 - val_loss: 5263922.5000 - val_mae: 1501.0255\n",
            "Epoch 495/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1397189.6198 - mae: 806.6937 - val_loss: 5525580.0000 - val_mae: 1577.6077\n",
            "Epoch 496/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1521396.7292 - mae: 880.7526 - val_loss: 5291908.0000 - val_mae: 1460.3096\n",
            "Epoch 497/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1630613.9219 - mae: 813.9439 - val_loss: 4985433.5000 - val_mae: 1478.4041\n",
            "Epoch 498/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2326718.0417 - mae: 923.1582 - val_loss: 5479381.0000 - val_mae: 1558.0863\n",
            "Epoch 499/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4384651.2917 - mae: 989.2983 - val_loss: 7270416.5000 - val_mae: 2000.5443\n",
            "Epoch 500/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5190700.8750 - mae: 1254.2195 - val_loss: 5596478.0000 - val_mae: 1646.5752\n",
            "Epoch 501/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1554364.8542 - mae: 930.4928 - val_loss: 6215606.0000 - val_mae: 1654.6243\n",
            "Epoch 502/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1855589.7188 - mae: 1002.0893 - val_loss: 5716047.0000 - val_mae: 1603.1268\n",
            "Epoch 503/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3805701.3125 - mae: 1105.2805 - val_loss: 4494346.5000 - val_mae: 1511.7279\n",
            "Epoch 504/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2583529.7292 - mae: 982.5484 - val_loss: 6362536.5000 - val_mae: 1629.4886\n",
            "Epoch 505/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2724433.8438 - mae: 1006.8598 - val_loss: 7234139.5000 - val_mae: 1851.2688\n",
            "Epoch 506/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3638111.3958 - mae: 1130.5056 - val_loss: 5208638.0000 - val_mae: 1450.4818\n",
            "Epoch 507/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2566963.9896 - mae: 903.8704 - val_loss: 5887167.5000 - val_mae: 1577.9834\n",
            "Epoch 508/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1300203.3750 - mae: 813.1351 - val_loss: 5986703.0000 - val_mae: 1594.7048\n",
            "Epoch 509/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2504495.4062 - mae: 993.4943 - val_loss: 5391443.5000 - val_mae: 1507.6565\n",
            "Epoch 510/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4677464.8958 - mae: 1129.7016 - val_loss: 4826788.5000 - val_mae: 1523.5272\n",
            "Epoch 511/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1704873.7708 - mae: 839.3568 - val_loss: 6804594.0000 - val_mae: 1693.3896\n",
            "Epoch 512/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3011995.5729 - mae: 1080.9934 - val_loss: 6718214.5000 - val_mae: 1759.1925\n",
            "Epoch 513/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3530883.5417 - mae: 1173.3562 - val_loss: 5400468.5000 - val_mae: 1515.1633\n",
            "Epoch 514/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2153337.0208 - mae: 1036.4416 - val_loss: 6714419.0000 - val_mae: 1611.1868\n",
            "Epoch 515/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2775287.0417 - mae: 930.0210 - val_loss: 4668258.5000 - val_mae: 1452.9829\n",
            "Epoch 516/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3644372.1042 - mae: 1039.1027 - val_loss: 5368184.0000 - val_mae: 1495.4515\n",
            "Epoch 517/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2153682.1458 - mae: 969.2389 - val_loss: 7365431.0000 - val_mae: 1809.6814\n",
            "Epoch 518/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4788659.6875 - mae: 1201.0754 - val_loss: 5249259.5000 - val_mae: 1446.7717\n",
            "Epoch 519/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2216234.4583 - mae: 922.8128 - val_loss: 6147970.0000 - val_mae: 1707.2620\n",
            "Epoch 520/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2134476.5729 - mae: 1092.7166 - val_loss: 7145017.5000 - val_mae: 1624.3140\n",
            "Epoch 521/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2427271.2917 - mae: 965.1265 - val_loss: 5531897.5000 - val_mae: 1553.1377\n",
            "Epoch 522/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1971457.0312 - mae: 879.4727 - val_loss: 5939115.0000 - val_mae: 1581.2579\n",
            "Epoch 523/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2641492.0833 - mae: 844.3471 - val_loss: 6344221.0000 - val_mae: 1571.7981\n",
            "Epoch 524/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1858426.0521 - mae: 861.2939 - val_loss: 6448751.0000 - val_mae: 1530.9380\n",
            "Epoch 525/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1739288.1250 - mae: 836.8532 - val_loss: 6127498.5000 - val_mae: 1528.7391\n",
            "Epoch 526/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2582224.4062 - mae: 862.9121 - val_loss: 6704444.5000 - val_mae: 1754.6447\n",
            "Epoch 527/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2185809.2396 - mae: 967.7921 - val_loss: 6609936.5000 - val_mae: 1551.1344\n",
            "Epoch 528/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1756322.5885 - mae: 790.6893 - val_loss: 7375326.0000 - val_mae: 1606.0280\n",
            "Epoch 529/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2168625.5573 - mae: 818.3297 - val_loss: 6439756.0000 - val_mae: 1553.3252\n",
            "Epoch 530/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2144735.7344 - mae: 829.8609 - val_loss: 6937398.0000 - val_mae: 1710.6855\n",
            "Epoch 531/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2047333.0000 - mae: 854.7350 - val_loss: 6520011.5000 - val_mae: 1533.5652\n",
            "Epoch 532/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1114376.0000 - mae: 762.5673 - val_loss: 6709567.5000 - val_mae: 1574.2756\n",
            "Epoch 533/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1225793.6198 - mae: 763.5238 - val_loss: 6044883.0000 - val_mae: 1527.8175\n",
            "Epoch 534/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1900074.0729 - mae: 800.9539 - val_loss: 6073389.0000 - val_mae: 1528.1152\n",
            "Epoch 535/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2986849.9688 - mae: 868.6959 - val_loss: 6471222.0000 - val_mae: 1582.7814\n",
            "Epoch 536/1000\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 1768362.9792 - mae: 850.5309 - val_loss: 7657442.5000 - val_mae: 1709.2634\n",
            "Epoch 537/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2014185.1562 - mae: 971.9201 - val_loss: 7907135.5000 - val_mae: 1695.9167\n",
            "Epoch 538/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4296017.1042 - mae: 1063.7047 - val_loss: 8173145.0000 - val_mae: 1947.7189\n",
            "Epoch 539/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2372232.6771 - mae: 1189.7922 - val_loss: 6963476.5000 - val_mae: 1609.7511\n",
            "Epoch 540/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1813772.3854 - mae: 965.5374 - val_loss: 7821413.5000 - val_mae: 1724.8429\n",
            "Epoch 541/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1499416.3438 - mae: 869.2356 - val_loss: 7683615.0000 - val_mae: 1644.1954\n",
            "Epoch 542/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2606229.2812 - mae: 898.4691 - val_loss: 6041754.5000 - val_mae: 1483.3896\n",
            "Epoch 543/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1842831.4531 - mae: 761.9356 - val_loss: 8248415.5000 - val_mae: 1664.2365\n",
            "Epoch 544/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4452810.7292 - mae: 1355.0378 - val_loss: 12219849.0000 - val_mae: 2340.4985\n",
            "Epoch 545/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6144582.9167 - mae: 1674.6630 - val_loss: 13245974.0000 - val_mae: 2507.7383\n",
            "Epoch 546/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5137440.7500 - mae: 1548.6637 - val_loss: 7108527.5000 - val_mae: 1744.0929\n",
            "Epoch 547/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3343031.4583 - mae: 1247.2633 - val_loss: 5707535.0000 - val_mae: 1541.4686\n",
            "Epoch 548/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2053558.0833 - mae: 1028.0600 - val_loss: 6576387.0000 - val_mae: 1528.9834\n",
            "Epoch 549/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1649556.0312 - mae: 897.0308 - val_loss: 6516623.5000 - val_mae: 1577.1051\n",
            "Epoch 550/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1436705.2604 - mae: 770.1933 - val_loss: 6615239.0000 - val_mae: 1520.6389\n",
            "Epoch 551/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1436550.8021 - mae: 780.0973 - val_loss: 6765867.5000 - val_mae: 1611.8867\n",
            "Epoch 552/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4041613.7500 - mae: 1005.7534 - val_loss: 6699025.0000 - val_mae: 1556.4703\n",
            "Epoch 553/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3727941.7917 - mae: 884.6553 - val_loss: 5757231.0000 - val_mae: 1466.3103\n",
            "Epoch 554/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3739291.8021 - mae: 866.0048 - val_loss: 6762338.5000 - val_mae: 1501.0085\n",
            "Epoch 555/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1528684.9167 - mae: 700.2756 - val_loss: 6575301.5000 - val_mae: 1525.4371\n",
            "Epoch 556/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3816610.2917 - mae: 917.2074 - val_loss: 7118709.5000 - val_mae: 1594.4314\n",
            "Epoch 557/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3681891.4479 - mae: 860.0176 - val_loss: 5812348.5000 - val_mae: 1478.1418\n",
            "Epoch 558/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1426663.4219 - mae: 784.2419 - val_loss: 6662927.0000 - val_mae: 1477.0703\n",
            "Epoch 559/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2648588.8125 - mae: 761.6426 - val_loss: 6858832.5000 - val_mae: 1529.3210\n",
            "Epoch 560/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1138074.3073 - mae: 704.4030 - val_loss: 6836264.5000 - val_mae: 1536.1863\n",
            "Epoch 561/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1248839.0833 - mae: 705.4581 - val_loss: 7302604.0000 - val_mae: 1552.5040\n",
            "Epoch 562/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1811513.9323 - mae: 851.7480 - val_loss: 9559732.0000 - val_mae: 1996.6748\n",
            "Epoch 563/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2280055.8229 - mae: 1023.7008 - val_loss: 6633196.0000 - val_mae: 1579.3427\n",
            "Epoch 564/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3883926.3542 - mae: 932.1872 - val_loss: 6122187.5000 - val_mae: 1476.2054\n",
            "Epoch 565/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3031185.3021 - mae: 911.4428 - val_loss: 7031723.0000 - val_mae: 1644.1886\n",
            "Epoch 566/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1850384.3854 - mae: 881.0867 - val_loss: 6166419.0000 - val_mae: 1470.9984\n",
            "Epoch 567/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1766813.3542 - mae: 867.4503 - val_loss: 6825213.0000 - val_mae: 1561.9263\n",
            "Epoch 568/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1321161.5885 - mae: 777.2439 - val_loss: 7045383.5000 - val_mae: 1574.3325\n",
            "Epoch 569/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1524704.4896 - mae: 768.5365 - val_loss: 7164093.5000 - val_mae: 1547.3286\n",
            "Epoch 570/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2006410.7292 - mae: 760.8099 - val_loss: 7004253.0000 - val_mae: 1552.0690\n",
            "Epoch 571/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2129671.5104 - mae: 902.2430 - val_loss: 7498571.5000 - val_mae: 1606.0874\n",
            "Epoch 572/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2857712.6875 - mae: 841.3632 - val_loss: 6379944.5000 - val_mae: 1509.2002\n",
            "Epoch 573/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1959585.5312 - mae: 845.1258 - val_loss: 7302350.5000 - val_mae: 1649.5391\n",
            "Epoch 574/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1891942.8750 - mae: 851.1694 - val_loss: 7421961.0000 - val_mae: 1645.4646\n",
            "Epoch 575/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1560142.4896 - mae: 876.1204 - val_loss: 6986852.5000 - val_mae: 1581.2460\n",
            "Epoch 576/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2843566.5521 - mae: 838.1687 - val_loss: 7804556.5000 - val_mae: 1648.9779\n",
            "Epoch 577/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1599739.3542 - mae: 782.4561 - val_loss: 7427473.0000 - val_mae: 1671.3120\n",
            "Epoch 578/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1437895.5052 - mae: 894.4135 - val_loss: 8088365.0000 - val_mae: 1709.0455\n",
            "Epoch 579/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2461594.8594 - mae: 875.1323 - val_loss: 7244756.5000 - val_mae: 1569.7572\n",
            "Epoch 580/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3751123.6250 - mae: 916.0487 - val_loss: 6815435.5000 - val_mae: 1540.6171\n",
            "Epoch 581/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1551826.2396 - mae: 728.2728 - val_loss: 6606568.5000 - val_mae: 1482.7092\n",
            "Epoch 582/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 969307.9219 - mae: 691.9232 - val_loss: 6804468.0000 - val_mae: 1539.8674\n",
            "Epoch 583/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1992201.4688 - mae: 773.4459 - val_loss: 6517958.5000 - val_mae: 1525.6947\n",
            "Epoch 584/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1677921.7604 - mae: 775.3637 - val_loss: 8070617.5000 - val_mae: 1692.4747\n",
            "Epoch 585/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1582831.8177 - mae: 868.7938 - val_loss: 8204069.5000 - val_mae: 1910.9420\n",
            "Epoch 586/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2455749.0625 - mae: 1034.0382 - val_loss: 7220276.0000 - val_mae: 1726.5762\n",
            "Epoch 587/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1586734.1146 - mae: 927.2978 - val_loss: 6456017.5000 - val_mae: 1531.5304\n",
            "Epoch 588/1000\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 2844705.0000 - mae: 849.3602 - val_loss: 7819281.0000 - val_mae: 1649.4777\n",
            "Epoch 589/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2864902.5312 - mae: 829.8044 - val_loss: 7925891.5000 - val_mae: 1575.2383\n",
            "Epoch 590/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1787809.8281 - mae: 779.3404 - val_loss: 9626244.0000 - val_mae: 1976.8506\n",
            "Epoch 591/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2070860.5417 - mae: 982.2572 - val_loss: 8791511.0000 - val_mae: 1803.3912\n",
            "Epoch 592/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2269865.0938 - mae: 948.9175 - val_loss: 9146916.0000 - val_mae: 1872.7981\n",
            "Epoch 593/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4718619.9375 - mae: 1144.8264 - val_loss: 12358916.0000 - val_mae: 2536.0129\n",
            "Epoch 594/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8477546.1250 - mae: 2020.1261 - val_loss: 9851984.0000 - val_mae: 1976.0398\n",
            "Epoch 595/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9779008.9583 - mae: 2393.3065 - val_loss: 12273019.0000 - val_mae: 2340.7966\n",
            "Epoch 596/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4347983.1875 - mae: 1443.8044 - val_loss: 7287905.0000 - val_mae: 1798.6960\n",
            "Epoch 597/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7904738.9167 - mae: 1602.7914 - val_loss: 6303963.0000 - val_mae: 1821.8595\n",
            "Epoch 598/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4940573.0833 - mae: 1451.8980 - val_loss: 8654974.0000 - val_mae: 1972.9432\n",
            "Epoch 599/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3162867.4583 - mae: 1268.3352 - val_loss: 8116958.0000 - val_mae: 1821.4863\n",
            "Epoch 600/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4333524.0000 - mae: 1169.2055 - val_loss: 5863903.5000 - val_mae: 1673.3335\n",
            "Epoch 601/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4007180.9792 - mae: 1225.2770 - val_loss: 8383948.0000 - val_mae: 1726.0139\n",
            "Epoch 602/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2679027.2500 - mae: 1146.7352 - val_loss: 8113269.0000 - val_mae: 1863.0221\n",
            "Epoch 603/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2723780.0833 - mae: 1226.4139 - val_loss: 8406695.0000 - val_mae: 1812.5297\n",
            "Epoch 604/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3771356.2500 - mae: 1134.0933 - val_loss: 6734300.5000 - val_mae: 1527.1831\n",
            "Epoch 605/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1472861.2760 - mae: 868.7283 - val_loss: 7219560.5000 - val_mae: 1518.2823\n",
            "Epoch 606/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1922688.5417 - mae: 827.9785 - val_loss: 6412347.0000 - val_mae: 1460.7863\n",
            "Epoch 607/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1434911.0156 - mae: 802.2737 - val_loss: 7664751.0000 - val_mae: 1609.6251\n",
            "Epoch 608/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1456530.9062 - mae: 780.3313 - val_loss: 7411306.5000 - val_mae: 1573.6725\n",
            "Epoch 609/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1873394.8281 - mae: 795.9315 - val_loss: 8146478.0000 - val_mae: 1622.0878\n",
            "Epoch 610/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1211896.6875 - mae: 786.4457 - val_loss: 6922858.5000 - val_mae: 1472.5068\n",
            "Epoch 611/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3674520.4792 - mae: 862.7818 - val_loss: 7775969.0000 - val_mae: 1622.9762\n",
            "Epoch 612/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2016004.9635 - mae: 779.7421 - val_loss: 7755197.5000 - val_mae: 1556.6615\n",
            "Epoch 613/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1661839.6667 - mae: 697.4469 - val_loss: 7060938.0000 - val_mae: 1501.9954\n",
            "Epoch 614/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1536312.1719 - mae: 717.5797 - val_loss: 8197485.0000 - val_mae: 1624.0717\n",
            "Epoch 615/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1895232.1615 - mae: 736.9478 - val_loss: 7909701.0000 - val_mae: 1560.5734\n",
            "Epoch 616/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2650544.5990 - mae: 753.6720 - val_loss: 8341038.5000 - val_mae: 1674.8939\n",
            "Epoch 617/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1495873.5677 - mae: 784.8453 - val_loss: 7136794.5000 - val_mae: 1508.2338\n",
            "Epoch 618/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1424634.2135 - mae: 729.7216 - val_loss: 7120741.5000 - val_mae: 1525.6973\n",
            "Epoch 619/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 904690.4479 - mae: 663.5991 - val_loss: 7651526.5000 - val_mae: 1534.2283\n",
            "Epoch 620/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1537861.7031 - mae: 734.5818 - val_loss: 7094019.5000 - val_mae: 1471.3491\n",
            "Epoch 621/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3413783.4271 - mae: 752.9691 - val_loss: 7476147.0000 - val_mae: 1643.9646\n",
            "Epoch 622/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3612571.9479 - mae: 854.0969 - val_loss: 7748192.0000 - val_mae: 1721.5748\n",
            "Epoch 623/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1249091.3490 - mae: 828.3256 - val_loss: 8032507.0000 - val_mae: 1543.5470\n",
            "Epoch 624/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2289273.8906 - mae: 803.1055 - val_loss: 7509170.5000 - val_mae: 1606.8461\n",
            "Epoch 625/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1219790.4010 - mae: 744.0519 - val_loss: 6914142.5000 - val_mae: 1461.9924\n",
            "Epoch 626/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2541791.9479 - mae: 714.9170 - val_loss: 7112783.0000 - val_mae: 1481.1143\n",
            "Epoch 627/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1776506.7656 - mae: 668.7244 - val_loss: 7765007.5000 - val_mae: 1571.7843\n",
            "Epoch 628/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1637464.5625 - mae: 704.6918 - val_loss: 8254711.0000 - val_mae: 1546.4216\n",
            "Epoch 629/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3440808.8854 - mae: 771.7295 - val_loss: 8199375.0000 - val_mae: 1605.7534\n",
            "Epoch 630/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3517993.8438 - mae: 802.7087 - val_loss: 7699730.0000 - val_mae: 1532.3723\n",
            "Epoch 631/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1495500.1354 - mae: 717.1322 - val_loss: 8099260.0000 - val_mae: 1710.2244\n",
            "Epoch 632/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3599362.4792 - mae: 846.6147 - val_loss: 7577965.5000 - val_mae: 1563.0692\n",
            "Epoch 633/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3707710.3542 - mae: 889.7461 - val_loss: 7256224.5000 - val_mae: 1551.1171\n",
            "Epoch 634/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1701704.7500 - mae: 723.8348 - val_loss: 7304815.0000 - val_mae: 1516.5408\n",
            "Epoch 635/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1076770.0677 - mae: 677.2013 - val_loss: 7606352.0000 - val_mae: 1530.5090\n",
            "Epoch 636/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1048460.9792 - mae: 703.7852 - val_loss: 7501284.0000 - val_mae: 1551.5643\n",
            "Epoch 637/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1293632.8438 - mae: 740.9783 - val_loss: 8132683.5000 - val_mae: 1689.6510\n",
            "Epoch 638/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2161481.9062 - mae: 856.2330 - val_loss: 7126719.0000 - val_mae: 1467.1797\n",
            "Epoch 639/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1404018.9688 - mae: 664.3279 - val_loss: 7887352.5000 - val_mae: 1581.8826\n",
            "Epoch 640/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1409630.1198 - mae: 749.4346 - val_loss: 8112461.0000 - val_mae: 1575.2195\n",
            "Epoch 641/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2628427.5729 - mae: 759.5058 - val_loss: 7573280.0000 - val_mae: 1577.9797\n",
            "Epoch 642/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1660746.5208 - mae: 692.0797 - val_loss: 8521973.0000 - val_mae: 1741.6667\n",
            "Epoch 643/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1189370.7656 - mae: 815.4397 - val_loss: 7460554.0000 - val_mae: 1552.2651\n",
            "Epoch 644/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1363097.4792 - mae: 715.1140 - val_loss: 8402761.0000 - val_mae: 1550.6300\n",
            "Epoch 645/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2654322.5312 - mae: 763.8503 - val_loss: 6698506.5000 - val_mae: 1469.8433\n",
            "Epoch 646/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 827228.5521 - mae: 647.5859 - val_loss: 7403916.5000 - val_mae: 1533.8295\n",
            "Epoch 647/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1709380.6927 - mae: 749.3823 - val_loss: 7545789.5000 - val_mae: 1529.2662\n",
            "Epoch 648/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1076876.8281 - mae: 675.3671 - val_loss: 7488847.0000 - val_mae: 1532.8855\n",
            "Epoch 649/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1439462.3385 - mae: 838.1522 - val_loss: 8855697.0000 - val_mae: 1658.2234\n",
            "Epoch 650/1000\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 1764165.5417 - mae: 837.6583 - val_loss: 8954664.0000 - val_mae: 1747.7135\n",
            "Epoch 651/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2442143.9167 - mae: 963.4759 - val_loss: 7208116.0000 - val_mae: 1570.0671\n",
            "Epoch 652/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2177272.5000 - mae: 743.7956 - val_loss: 7308824.5000 - val_mae: 1558.5516\n",
            "Epoch 653/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1708629.4427 - mae: 735.2549 - val_loss: 7604504.5000 - val_mae: 1521.5885\n",
            "Epoch 654/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1110759.2552 - mae: 694.3181 - val_loss: 7489115.5000 - val_mae: 1505.6539\n",
            "Epoch 655/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1781796.9010 - mae: 646.5760 - val_loss: 8421647.0000 - val_mae: 1631.2854\n",
            "Epoch 656/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 947274.9115 - mae: 718.6634 - val_loss: 7745997.5000 - val_mae: 1573.5098\n",
            "Epoch 657/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3489099.8750 - mae: 813.0658 - val_loss: 7584937.5000 - val_mae: 1547.6355\n",
            "Epoch 658/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1106805.5729 - mae: 653.6446 - val_loss: 8205852.0000 - val_mae: 1618.2894\n",
            "Epoch 659/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3466539.4479 - mae: 797.6469 - val_loss: 7678607.5000 - val_mae: 1537.2153\n",
            "Epoch 660/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1409318.5677 - mae: 681.2121 - val_loss: 8194675.5000 - val_mae: 1542.1317\n",
            "Epoch 661/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3346112.0521 - mae: 716.9171 - val_loss: 8407477.0000 - val_mae: 1776.2717\n",
            "Epoch 662/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1212929.2812 - mae: 780.7592 - val_loss: 10060324.0000 - val_mae: 2064.9050\n",
            "Epoch 663/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1631420.6354 - mae: 966.6529 - val_loss: 7711265.5000 - val_mae: 1598.4127\n",
            "Epoch 664/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 2228097.6771 - mae: 759.7444 - val_loss: 7630563.0000 - val_mae: 1593.4910\n",
            "Epoch 665/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2139259.4792 - mae: 714.6421 - val_loss: 8121916.0000 - val_mae: 1596.9484\n",
            "Epoch 666/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1048029.8854 - mae: 609.2013 - val_loss: 7915415.0000 - val_mae: 1551.2346\n",
            "Epoch 667/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 961039.3516 - mae: 634.2131 - val_loss: 7958598.5000 - val_mae: 1598.3000\n",
            "Epoch 668/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 995194.5052 - mae: 635.2023 - val_loss: 7531831.5000 - val_mae: 1621.8630\n",
            "Epoch 669/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1143895.7188 - mae: 671.5051 - val_loss: 7786118.0000 - val_mae: 1542.6360\n",
            "Epoch 670/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3457265.7708 - mae: 766.8859 - val_loss: 7814565.5000 - val_mae: 1588.8483\n",
            "Epoch 671/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2513590.7812 - mae: 687.1070 - val_loss: 7851825.0000 - val_mae: 1561.1613\n",
            "Epoch 672/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 894665.9896 - mae: 625.9471 - val_loss: 7584148.0000 - val_mae: 1532.6040\n",
            "Epoch 673/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1220250.6042 - mae: 643.1643 - val_loss: 7726523.0000 - val_mae: 1573.2738\n",
            "Epoch 674/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1707766.3958 - mae: 751.9505 - val_loss: 7754833.5000 - val_mae: 1550.3839\n",
            "Epoch 675/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1899181.4688 - mae: 734.8886 - val_loss: 9308076.0000 - val_mae: 1769.8414\n",
            "Epoch 676/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1358572.6354 - mae: 768.5754 - val_loss: 7643981.5000 - val_mae: 1552.2939\n",
            "Epoch 677/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3403869.2812 - mae: 749.8404 - val_loss: 8278867.5000 - val_mae: 1646.4758\n",
            "Epoch 678/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2626815.2500 - mae: 752.2144 - val_loss: 7852375.5000 - val_mae: 1577.2634\n",
            "Epoch 679/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3443351.2396 - mae: 747.2771 - val_loss: 7605336.0000 - val_mae: 1576.4857\n",
            "Epoch 680/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3492547.5312 - mae: 782.1476 - val_loss: 8384552.5000 - val_mae: 1684.8721\n",
            "Epoch 681/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2525938.5833 - mae: 849.5140 - val_loss: 7797063.0000 - val_mae: 1624.9165\n",
            "Epoch 682/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2388048.4167 - mae: 950.7899 - val_loss: 8427252.0000 - val_mae: 1648.6405\n",
            "Epoch 683/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1003088.9583 - mae: 695.6775 - val_loss: 8334018.0000 - val_mae: 1644.4812\n",
            "Epoch 684/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1609819.9583 - mae: 824.8041 - val_loss: 7261315.0000 - val_mae: 1607.5669\n",
            "Epoch 685/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1911323.5677 - mae: 817.5187 - val_loss: 7615607.0000 - val_mae: 1581.4728\n",
            "Epoch 686/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1187428.2396 - mae: 697.5567 - val_loss: 7819910.0000 - val_mae: 1532.5782\n",
            "Epoch 687/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1494984.1406 - mae: 710.6999 - val_loss: 8715817.0000 - val_mae: 1626.6389\n",
            "Epoch 688/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1905127.3594 - mae: 739.1783 - val_loss: 7889386.0000 - val_mae: 1559.4047\n",
            "Epoch 689/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1296071.6458 - mae: 680.6187 - val_loss: 8824752.0000 - val_mae: 1815.7006\n",
            "Epoch 690/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2809035.3750 - mae: 859.2615 - val_loss: 7684557.5000 - val_mae: 1672.1412\n",
            "Epoch 691/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2293655.5573 - mae: 809.0885 - val_loss: 7836779.5000 - val_mae: 1552.8036\n",
            "Epoch 692/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1038341.8906 - mae: 606.4145 - val_loss: 7789968.5000 - val_mae: 1509.5522\n",
            "Epoch 693/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2461091.1562 - mae: 687.5337 - val_loss: 7658749.0000 - val_mae: 1576.2466\n",
            "Epoch 694/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2178052.0677 - mae: 739.7941 - val_loss: 7485966.0000 - val_mae: 1534.1454\n",
            "Epoch 695/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1049297.7135 - mae: 622.7958 - val_loss: 7666516.5000 - val_mae: 1549.2874\n",
            "Epoch 696/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1642312.1510 - mae: 705.6838 - val_loss: 8521374.0000 - val_mae: 1690.8043\n",
            "Epoch 697/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1319166.8646 - mae: 798.2473 - val_loss: 8178167.0000 - val_mae: 1577.0616\n",
            "Epoch 698/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2171561.9479 - mae: 723.3616 - val_loss: 6939080.0000 - val_mae: 1579.1027\n",
            "Epoch 699/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2794772.4896 - mae: 827.0959 - val_loss: 8589197.0000 - val_mae: 1618.6156\n",
            "Epoch 700/1000\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 1668991.2344 - mae: 728.9409 - val_loss: 7514371.5000 - val_mae: 1529.8931\n",
            "Epoch 701/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3417670.4167 - mae: 771.9419 - val_loss: 8050444.0000 - val_mae: 1562.0643\n",
            "Epoch 702/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1696136.8854 - mae: 648.9146 - val_loss: 7945990.0000 - val_mae: 1551.4901\n",
            "Epoch 703/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3326524.6562 - mae: 720.5656 - val_loss: 6912350.5000 - val_mae: 1504.8884\n",
            "Epoch 704/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1293788.7292 - mae: 687.9851 - val_loss: 8083053.5000 - val_mae: 1566.8730\n",
            "Epoch 705/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3332670.7708 - mae: 706.4845 - val_loss: 7401237.5000 - val_mae: 1587.5076\n",
            "Epoch 706/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1096587.0677 - mae: 701.9372 - val_loss: 7326764.5000 - val_mae: 1533.1597\n",
            "Epoch 707/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1077481.9375 - mae: 680.7364 - val_loss: 7641053.0000 - val_mae: 1548.5690\n",
            "Epoch 708/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1230314.7917 - mae: 658.3566 - val_loss: 8532633.0000 - val_mae: 1694.3265\n",
            "Epoch 709/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1503526.4010 - mae: 732.4019 - val_loss: 7408376.5000 - val_mae: 1559.3668\n",
            "Epoch 710/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3549224.3125 - mae: 816.3297 - val_loss: 7725659.5000 - val_mae: 1643.9940\n",
            "Epoch 711/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1007278.1146 - mae: 714.6316 - val_loss: 7813160.0000 - val_mae: 1628.1755\n",
            "Epoch 712/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1048141.9219 - mae: 713.4753 - val_loss: 9118581.0000 - val_mae: 1739.5856\n",
            "Epoch 713/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1469098.9740 - mae: 776.4081 - val_loss: 7876343.0000 - val_mae: 1572.1536\n",
            "Epoch 714/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1971706.4792 - mae: 1047.5440 - val_loss: 8538723.0000 - val_mae: 1793.2828\n",
            "Epoch 715/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3251337.3229 - mae: 1159.8647 - val_loss: 8446682.0000 - val_mae: 1858.6204\n",
            "Epoch 716/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3780721.4792 - mae: 1187.5643 - val_loss: 8621781.0000 - val_mae: 1684.1912\n",
            "Epoch 717/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4271959.5000 - mae: 1112.3203 - val_loss: 8253477.0000 - val_mae: 1765.4619\n",
            "Epoch 718/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2676520.5000 - mae: 1134.8646 - val_loss: 6613473.0000 - val_mae: 1493.2987\n",
            "Epoch 719/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1777189.1823 - mae: 831.3699 - val_loss: 7764034.5000 - val_mae: 1548.6890\n",
            "Epoch 720/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1107382.4792 - mae: 786.7020 - val_loss: 7225768.5000 - val_mae: 1630.3623\n",
            "Epoch 721/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1492309.3021 - mae: 884.8369 - val_loss: 8318664.5000 - val_mae: 1689.0831\n",
            "Epoch 722/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2073688.4062 - mae: 856.6369 - val_loss: 7011491.0000 - val_mae: 1603.1804\n",
            "Epoch 723/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1321182.4896 - mae: 817.8010 - val_loss: 8337175.5000 - val_mae: 1727.1431\n",
            "Epoch 724/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2044543.2917 - mae: 872.1388 - val_loss: 6593431.0000 - val_mae: 1475.8394\n",
            "Epoch 725/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1044598.5938 - mae: 703.5723 - val_loss: 6793645.0000 - val_mae: 1515.2291\n",
            "Epoch 726/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2696102.1667 - mae: 784.4315 - val_loss: 7087183.0000 - val_mae: 1518.6913\n",
            "Epoch 727/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1300438.1875 - mae: 681.4633 - val_loss: 6893619.0000 - val_mae: 1469.0830\n",
            "Epoch 728/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1762446.8594 - mae: 651.6144 - val_loss: 8089652.0000 - val_mae: 1563.9832\n",
            "Epoch 729/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 916658.0677 - mae: 640.3820 - val_loss: 7269426.5000 - val_mae: 1519.2706\n",
            "Epoch 730/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 952827.9167 - mae: 663.1601 - val_loss: 7495063.0000 - val_mae: 1552.7124\n",
            "Epoch 731/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2769736.4896 - mae: 812.5579 - val_loss: 9520425.0000 - val_mae: 2158.3157\n",
            "Epoch 732/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6328177.1250 - mae: 1833.8977 - val_loss: 14980568.0000 - val_mae: 2637.1484\n",
            "Epoch 733/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3606456.9792 - mae: 1473.3761 - val_loss: 9666826.0000 - val_mae: 2082.8186\n",
            "Epoch 734/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4743507.6667 - mae: 1485.3194 - val_loss: 9426980.0000 - val_mae: 2334.3945\n",
            "Epoch 735/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4029188.5833 - mae: 1525.4030 - val_loss: 12428856.0000 - val_mae: 2718.6018\n",
            "Epoch 736/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5874819.8333 - mae: 1886.3117 - val_loss: 5922029.0000 - val_mae: 1737.3096\n",
            "Epoch 737/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3630200.0833 - mae: 1375.3360 - val_loss: 15362920.0000 - val_mae: 2662.9382\n",
            "Epoch 738/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5433662.7917 - mae: 1690.0062 - val_loss: 8447649.0000 - val_mae: 1848.3223\n",
            "Epoch 739/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4463648.3333 - mae: 1412.3566 - val_loss: 4468557.0000 - val_mae: 1528.7574\n",
            "Epoch 740/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 5932263.4375 - mae: 1247.8505 - val_loss: 8696771.0000 - val_mae: 1980.3140\n",
            "Epoch 741/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2854844.7812 - mae: 1163.9733 - val_loss: 5269527.5000 - val_mae: 1462.2595\n",
            "Epoch 742/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1860886.4375 - mae: 1018.1861 - val_loss: 7399860.5000 - val_mae: 1555.6405\n",
            "Epoch 743/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2321943.4271 - mae: 910.2948 - val_loss: 6976755.5000 - val_mae: 1604.9548\n",
            "Epoch 744/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1258892.7760 - mae: 807.1225 - val_loss: 7500429.5000 - val_mae: 1538.1333\n",
            "Epoch 745/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1254692.4896 - mae: 660.8110 - val_loss: 7254168.5000 - val_mae: 1492.7313\n",
            "Epoch 746/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 960885.6198 - mae: 666.3422 - val_loss: 6923188.5000 - val_mae: 1451.4247\n",
            "Epoch 747/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2060381.8802 - mae: 681.6187 - val_loss: 7125855.5000 - val_mae: 1442.9957\n",
            "Epoch 748/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 2148638.7917 - mae: 726.2663 - val_loss: 7559270.0000 - val_mae: 1528.9609\n",
            "Epoch 749/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1232220.9323 - mae: 636.7782 - val_loss: 7175322.5000 - val_mae: 1466.8584\n",
            "Epoch 750/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3438622.9688 - mae: 766.7601 - val_loss: 8305801.5000 - val_mae: 1645.6036\n",
            "Epoch 751/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1114831.5677 - mae: 719.9081 - val_loss: 7411758.5000 - val_mae: 1465.9739\n",
            "Epoch 752/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1485230.1615 - mae: 759.6242 - val_loss: 9397339.0000 - val_mae: 1789.0103\n",
            "Epoch 753/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2204990.5729 - mae: 891.6949 - val_loss: 7340765.0000 - val_mae: 1512.6909\n",
            "Epoch 754/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1062634.6562 - mae: 730.3790 - val_loss: 7216704.5000 - val_mae: 1472.5227\n",
            "Epoch 755/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1237198.0990 - mae: 663.3085 - val_loss: 7401103.0000 - val_mae: 1495.7800\n",
            "Epoch 756/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1353158.5521 - mae: 642.2365 - val_loss: 7133459.0000 - val_mae: 1455.3474\n",
            "Epoch 757/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1098454.9688 - mae: 645.3189 - val_loss: 7467521.5000 - val_mae: 1463.5616\n",
            "Epoch 758/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1204101.6250 - mae: 638.6930 - val_loss: 7614775.0000 - val_mae: 1505.8578\n",
            "Epoch 759/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2015983.8021 - mae: 653.5308 - val_loss: 7723839.5000 - val_mae: 1483.3640\n",
            "Epoch 760/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1029111.4792 - mae: 607.8308 - val_loss: 7519160.0000 - val_mae: 1486.7415\n",
            "Epoch 761/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 884910.2396 - mae: 615.8488 - val_loss: 7337740.0000 - val_mae: 1474.0621\n",
            "Epoch 762/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3358360.6458 - mae: 733.3881 - val_loss: 7855351.0000 - val_mae: 1602.4647\n",
            "Epoch 763/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1137784.7708 - mae: 658.6652 - val_loss: 8098029.0000 - val_mae: 1539.2856\n",
            "Epoch 764/1000\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 771992.0521 - mae: 619.2444 - val_loss: 7652612.5000 - val_mae: 1484.4451\n",
            "Epoch 765/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1344113.1771 - mae: 633.8852 - val_loss: 7124639.0000 - val_mae: 1463.3203\n",
            "Epoch 766/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 840351.8073 - mae: 598.0604 - val_loss: 7518851.0000 - val_mae: 1495.5437\n",
            "Epoch 767/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2378448.1354 - mae: 654.8360 - val_loss: 7572469.5000 - val_mae: 1494.5536\n",
            "Epoch 768/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1417332.0703 - mae: 596.3617 - val_loss: 7166435.0000 - val_mae: 1468.9116\n",
            "Epoch 769/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2422811.2865 - mae: 661.0265 - val_loss: 8061786.5000 - val_mae: 1621.1096\n",
            "Epoch 770/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2045885.1875 - mae: 684.5138 - val_loss: 7798438.5000 - val_mae: 1502.3043\n",
            "Epoch 771/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1605212.1432 - mae: 585.0377 - val_loss: 8023829.5000 - val_mae: 1565.9969\n",
            "Epoch 772/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2402690.4427 - mae: 649.6199 - val_loss: 7299826.0000 - val_mae: 1485.0099\n",
            "Epoch 773/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 899479.8828 - mae: 591.8201 - val_loss: 7293717.5000 - val_mae: 1443.3096\n",
            "Epoch 774/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1292448.7760 - mae: 604.2285 - val_loss: 7630699.5000 - val_mae: 1513.6627\n",
            "Epoch 775/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2691037.7760 - mae: 798.0762 - val_loss: 8330518.0000 - val_mae: 1709.5737\n",
            "Epoch 776/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1300896.0781 - mae: 866.0537 - val_loss: 8130093.0000 - val_mae: 1703.6954\n",
            "Epoch 777/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3910687.0625 - mae: 979.3339 - val_loss: 8828990.0000 - val_mae: 1671.0848\n",
            "Epoch 778/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1321449.7760 - mae: 738.8544 - val_loss: 7754346.5000 - val_mae: 1529.9331\n",
            "Epoch 779/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1019721.5208 - mae: 698.7622 - val_loss: 8102155.0000 - val_mae: 1607.8894\n",
            "Epoch 780/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2692798.6771 - mae: 802.5910 - val_loss: 7133782.5000 - val_mae: 1512.2572\n",
            "Epoch 781/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3571372.1042 - mae: 836.5446 - val_loss: 8865942.0000 - val_mae: 1777.7323\n",
            "Epoch 782/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2152524.1354 - mae: 818.9294 - val_loss: 7645162.0000 - val_mae: 1488.7080\n",
            "Epoch 783/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1246797.1771 - mae: 656.6848 - val_loss: 7350313.5000 - val_mae: 1532.3475\n",
            "Epoch 784/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3354467.7083 - mae: 744.8238 - val_loss: 7594459.5000 - val_mae: 1510.5524\n",
            "Epoch 785/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 850167.4635 - mae: 611.8889 - val_loss: 8108812.0000 - val_mae: 1597.1575\n",
            "Epoch 786/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1267855.1771 - mae: 680.4978 - val_loss: 7325694.5000 - val_mae: 1470.1620\n",
            "Epoch 787/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1863628.7969 - mae: 712.6050 - val_loss: 7447132.5000 - val_mae: 1502.9944\n",
            "Epoch 788/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1559273.7188 - mae: 825.6184 - val_loss: 8191676.5000 - val_mae: 1602.5856\n",
            "Epoch 789/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2586561.5781 - mae: 757.1367 - val_loss: 8247288.5000 - val_mae: 1678.5701\n",
            "Epoch 790/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2244042.0729 - mae: 768.4540 - val_loss: 7923049.0000 - val_mae: 1583.0741\n",
            "Epoch 791/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2509935.0833 - mae: 722.0481 - val_loss: 7385087.5000 - val_mae: 1464.0797\n",
            "Epoch 792/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 792866.2708 - mae: 585.7148 - val_loss: 7330961.0000 - val_mae: 1459.2291\n",
            "Epoch 793/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2329575.0781 - mae: 616.8093 - val_loss: 7496363.5000 - val_mae: 1483.0636\n",
            "Epoch 794/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1424828.2630 - mae: 608.2420 - val_loss: 7868358.5000 - val_mae: 1529.2360\n",
            "Epoch 795/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1905604.4349 - mae: 609.9011 - val_loss: 7668953.0000 - val_mae: 1542.7112\n",
            "Epoch 796/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 734067.5885 - mae: 556.1916 - val_loss: 7615704.0000 - val_mae: 1490.9231\n",
            "Epoch 797/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3214540.9688 - mae: 665.8289 - val_loss: 7842373.0000 - val_mae: 1559.9720\n",
            "Epoch 798/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1102943.9167 - mae: 638.5157 - val_loss: 8234428.0000 - val_mae: 1602.3223\n",
            "Epoch 799/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2024125.4896 - mae: 657.7873 - val_loss: 7929331.5000 - val_mae: 1569.3046\n",
            "Epoch 800/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1068806.7969 - mae: 629.3899 - val_loss: 7857988.0000 - val_mae: 1574.9955\n",
            "Epoch 801/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1129467.1771 - mae: 667.5526 - val_loss: 7181324.0000 - val_mae: 1477.3633\n",
            "Epoch 802/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1940371.2344 - mae: 609.3313 - val_loss: 7720343.0000 - val_mae: 1515.3953\n",
            "Epoch 803/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 860688.7917 - mae: 575.3963 - val_loss: 7530654.5000 - val_mae: 1545.8035\n",
            "Epoch 804/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2366831.8906 - mae: 643.2186 - val_loss: 7374139.0000 - val_mae: 1508.5441\n",
            "Epoch 805/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1955263.0026 - mae: 626.2062 - val_loss: 7089531.0000 - val_mae: 1495.1074\n",
            "Epoch 806/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 801559.8802 - mae: 596.5887 - val_loss: 7465520.0000 - val_mae: 1522.4503\n",
            "Epoch 807/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1231912.8073 - mae: 585.4522 - val_loss: 7966761.5000 - val_mae: 1552.8102\n",
            "Epoch 808/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1676614.2552 - mae: 612.6543 - val_loss: 7525325.5000 - val_mae: 1504.0970\n",
            "Epoch 809/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 871427.7656 - mae: 622.9288 - val_loss: 7756539.0000 - val_mae: 1530.4062\n",
            "Epoch 810/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 787471.5625 - mae: 578.1012 - val_loss: 7348825.0000 - val_mae: 1497.1771\n",
            "Epoch 811/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1033823.2943 - mae: 608.2077 - val_loss: 7828273.0000 - val_mae: 1535.9865\n",
            "Epoch 812/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1101453.1927 - mae: 641.5570 - val_loss: 9018984.0000 - val_mae: 1681.2861\n",
            "Epoch 813/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1184612.1771 - mae: 806.8582 - val_loss: 8167415.0000 - val_mae: 1832.4213\n",
            "Epoch 814/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1678733.7656 - mae: 872.8962 - val_loss: 8190804.5000 - val_mae: 1622.7598\n",
            "Epoch 815/1000\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 2106369.7708 - mae: 826.7481 - val_loss: 9394832.0000 - val_mae: 1731.8318\n",
            "Epoch 816/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3147348.2396 - mae: 995.0372 - val_loss: 8336658.5000 - val_mae: 1933.4574\n",
            "Epoch 817/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5027882.1250 - mae: 1366.6606 - val_loss: 7858647.5000 - val_mae: 1718.2458\n",
            "Epoch 818/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1987681.0417 - mae: 973.2793 - val_loss: 7684207.5000 - val_mae: 1595.1935\n",
            "Epoch 819/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2448220.5000 - mae: 1046.9075 - val_loss: 6031188.5000 - val_mae: 1541.7015\n",
            "Epoch 820/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2930381.1667 - mae: 1293.2228 - val_loss: 9172274.0000 - val_mae: 1838.9141\n",
            "Epoch 821/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3428377.5729 - mae: 1211.3132 - val_loss: 7947307.5000 - val_mae: 1799.4216\n",
            "Epoch 822/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2738956.1875 - mae: 1084.3714 - val_loss: 8960598.0000 - val_mae: 1798.3309\n",
            "Epoch 823/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2063079.8542 - mae: 924.5259 - val_loss: 6719395.5000 - val_mae: 1629.6780\n",
            "Epoch 824/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3804007.1042 - mae: 928.5299 - val_loss: 6135787.5000 - val_mae: 1412.2900\n",
            "Epoch 825/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2624832.8854 - mae: 775.0860 - val_loss: 7617470.0000 - val_mae: 1675.6499\n",
            "Epoch 826/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3683702.0104 - mae: 885.0548 - val_loss: 7841888.0000 - val_mae: 1488.5031\n",
            "Epoch 827/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 983775.3958 - mae: 628.3148 - val_loss: 7467811.5000 - val_mae: 1504.2261\n",
            "Epoch 828/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1005931.4089 - mae: 595.1463 - val_loss: 7433040.0000 - val_mae: 1538.2587\n",
            "Epoch 829/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1220387.4010 - mae: 718.8127 - val_loss: 7681299.0000 - val_mae: 1512.9227\n",
            "Epoch 830/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1213975.1927 - mae: 750.8969 - val_loss: 7347862.0000 - val_mae: 1537.4515\n",
            "Epoch 831/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2803506.5417 - mae: 855.1469 - val_loss: 7723466.5000 - val_mae: 1492.8075\n",
            "Epoch 832/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 829248.2188 - mae: 642.3023 - val_loss: 7593441.0000 - val_mae: 1515.2308\n",
            "Epoch 833/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 820102.6615 - mae: 596.0551 - val_loss: 7758269.5000 - val_mae: 1535.5244\n",
            "Epoch 834/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1528287.9062 - mae: 659.7460 - val_loss: 7748011.5000 - val_mae: 1524.7699\n",
            "Epoch 835/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1929564.3854 - mae: 622.1051 - val_loss: 7065259.5000 - val_mae: 1450.7148\n",
            "Epoch 836/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1939346.9635 - mae: 616.1797 - val_loss: 7536569.0000 - val_mae: 1497.8918\n",
            "Epoch 837/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1632255.6953 - mae: 598.3316 - val_loss: 7012864.0000 - val_mae: 1480.1788\n",
            "Epoch 838/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1061964.8516 - mae: 563.9753 - val_loss: 6866955.0000 - val_mae: 1443.2440\n",
            "Epoch 839/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2335444.5156 - mae: 610.4957 - val_loss: 7893453.0000 - val_mae: 1532.1481\n",
            "Epoch 840/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2319957.5859 - mae: 608.1533 - val_loss: 7488322.0000 - val_mae: 1481.6108\n",
            "Epoch 841/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1087771.3073 - mae: 585.5944 - val_loss: 7301695.0000 - val_mae: 1460.3286\n",
            "Epoch 842/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1578834.3385 - mae: 576.2873 - val_loss: 7163344.0000 - val_mae: 1478.1609\n",
            "Epoch 843/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1246955.7552 - mae: 600.9511 - val_loss: 7946061.5000 - val_mae: 1577.0748\n",
            "Epoch 844/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 2567046.1042 - mae: 734.8256 - val_loss: 7273778.5000 - val_mae: 1520.7211\n",
            "Epoch 845/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 915654.9115 - mae: 648.4138 - val_loss: 7702653.0000 - val_mae: 1517.2249\n",
            "Epoch 846/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 855169.4167 - mae: 624.6188 - val_loss: 7135903.0000 - val_mae: 1474.0452\n",
            "Epoch 847/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 939349.4896 - mae: 606.4855 - val_loss: 7422934.0000 - val_mae: 1472.6418\n",
            "Epoch 848/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3235161.3438 - mae: 680.7487 - val_loss: 7383737.0000 - val_mae: 1483.4589\n",
            "Epoch 849/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1927183.1562 - mae: 617.3809 - val_loss: 7703168.5000 - val_mae: 1502.9304\n",
            "Epoch 850/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1902140.1302 - mae: 582.4032 - val_loss: 7194824.0000 - val_mae: 1477.5226\n",
            "Epoch 851/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2384548.7396 - mae: 647.0893 - val_loss: 7709387.5000 - val_mae: 1545.4597\n",
            "Epoch 852/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1250223.1875 - mae: 669.2572 - val_loss: 8202003.0000 - val_mae: 1759.2214\n",
            "Epoch 853/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1549800.5000 - mae: 814.4789 - val_loss: 8336456.5000 - val_mae: 1686.2180\n",
            "Epoch 854/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2802823.3750 - mae: 967.1225 - val_loss: 9660324.0000 - val_mae: 1815.0505\n",
            "Epoch 855/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2149030.5938 - mae: 890.6648 - val_loss: 9640958.0000 - val_mae: 1645.3667\n",
            "Epoch 856/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1650883.0312 - mae: 839.2412 - val_loss: 7682193.0000 - val_mae: 1647.7692\n",
            "Epoch 857/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3524065.8333 - mae: 1072.0243 - val_loss: 17275890.0000 - val_mae: 3001.5095\n",
            "Epoch 858/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 10357574.6667 - mae: 2106.4153 - val_loss: 9773883.0000 - val_mae: 2187.2515\n",
            "Epoch 859/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 5767069.7083 - mae: 1704.1752 - val_loss: 8599398.0000 - val_mae: 1828.7053\n",
            "Epoch 860/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3785760.4167 - mae: 1400.0654 - val_loss: 9277311.0000 - val_mae: 1902.5994\n",
            "Epoch 861/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 5457914.0417 - mae: 1579.5679 - val_loss: 9042030.0000 - val_mae: 1839.7109\n",
            "Epoch 862/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3542003.1875 - mae: 1336.4662 - val_loss: 9992593.0000 - val_mae: 2076.1113\n",
            "Epoch 863/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 5138682.9167 - mae: 1463.5566 - val_loss: 5650619.0000 - val_mae: 1528.5229\n",
            "Epoch 864/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3144100.2708 - mae: 1157.6899 - val_loss: 8136239.5000 - val_mae: 1661.2655\n",
            "Epoch 865/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1867471.4271 - mae: 889.2640 - val_loss: 9186027.0000 - val_mae: 1873.7854\n",
            "Epoch 866/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2240921.5312 - mae: 1043.2275 - val_loss: 7725699.0000 - val_mae: 1661.7977\n",
            "Epoch 867/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3500224.8021 - mae: 1275.7773 - val_loss: 10122751.0000 - val_mae: 2081.6011\n",
            "Epoch 868/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3440492.1042 - mae: 1303.2606 - val_loss: 7268719.0000 - val_mae: 1608.2395\n",
            "Epoch 869/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2845607.0729 - mae: 954.7352 - val_loss: 7675201.0000 - val_mae: 1748.2098\n",
            "Epoch 870/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1903653.1667 - mae: 854.9720 - val_loss: 8164884.5000 - val_mae: 1660.0482\n",
            "Epoch 871/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2062008.8854 - mae: 798.5060 - val_loss: 7876506.5000 - val_mae: 1659.1630\n",
            "Epoch 872/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2646671.1771 - mae: 751.1888 - val_loss: 7720651.5000 - val_mae: 1565.8713\n",
            "Epoch 873/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1685522.7708 - mae: 730.9296 - val_loss: 7428289.0000 - val_mae: 1571.4954\n",
            "Epoch 874/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2147913.8073 - mae: 708.0542 - val_loss: 8209908.0000 - val_mae: 1596.8506\n",
            "Epoch 875/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1374358.5417 - mae: 695.9733 - val_loss: 8181826.0000 - val_mae: 1601.8828\n",
            "Epoch 876/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1380030.1198 - mae: 700.6862 - val_loss: 7288309.5000 - val_mae: 1527.7941\n",
            "Epoch 877/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1019048.6562 - mae: 689.2507 - val_loss: 8197953.0000 - val_mae: 1635.0178\n",
            "Epoch 878/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1488897.9531 - mae: 748.0255 - val_loss: 7498493.0000 - val_mae: 1587.2902\n",
            "Epoch 879/1000\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 1416597.3854 - mae: 796.4900 - val_loss: 8511833.0000 - val_mae: 1643.0433\n",
            "Epoch 880/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3517856.9583 - mae: 808.8147 - val_loss: 8523381.0000 - val_mae: 1651.5859\n",
            "Epoch 881/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2130656.0208 - mae: 818.8731 - val_loss: 9024269.0000 - val_mae: 1688.1074\n",
            "Epoch 882/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1414774.5469 - mae: 859.8451 - val_loss: 8683425.0000 - val_mae: 1731.0592\n",
            "Epoch 883/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2063491.7812 - mae: 990.3040 - val_loss: 7046125.0000 - val_mae: 1595.5852\n",
            "Epoch 884/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1770111.1771 - mae: 804.3614 - val_loss: 7651752.0000 - val_mae: 1598.5712\n",
            "Epoch 885/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2963280.4948 - mae: 844.4553 - val_loss: 7806237.0000 - val_mae: 1597.6908\n",
            "Epoch 886/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1146143.1250 - mae: 751.8759 - val_loss: 9129931.0000 - val_mae: 1705.1122\n",
            "Epoch 887/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1411826.9010 - mae: 766.6480 - val_loss: 7784162.5000 - val_mae: 1519.7904\n",
            "Epoch 888/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1088760.6094 - mae: 627.6724 - val_loss: 7798940.0000 - val_mae: 1513.9432\n",
            "Epoch 889/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1174597.8281 - mae: 615.5457 - val_loss: 8301128.5000 - val_mae: 1672.0929\n",
            "Epoch 890/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1354731.2812 - mae: 726.3815 - val_loss: 8414560.0000 - val_mae: 1600.3262\n",
            "Epoch 891/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1835398.3594 - mae: 778.0902 - val_loss: 9260215.0000 - val_mae: 1744.3566\n",
            "Epoch 892/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1463242.8229 - mae: 815.5256 - val_loss: 8193364.5000 - val_mae: 1620.4235\n",
            "Epoch 893/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2165453.5521 - mae: 728.6388 - val_loss: 8357413.0000 - val_mae: 1667.1995\n",
            "Epoch 894/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1321309.8594 - mae: 744.6850 - val_loss: 8685348.0000 - val_mae: 1740.7885\n",
            "Epoch 895/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1175590.5000 - mae: 746.8903 - val_loss: 7777424.5000 - val_mae: 1576.9502\n",
            "Epoch 896/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1080407.1302 - mae: 710.0417 - val_loss: 8644427.0000 - val_mae: 1605.6445\n",
            "Epoch 897/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1257645.1146 - mae: 718.7204 - val_loss: 7504030.5000 - val_mae: 1607.7023\n",
            "Epoch 898/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 932174.7760 - mae: 651.6410 - val_loss: 8184227.0000 - val_mae: 1582.0775\n",
            "Epoch 899/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1680307.5521 - mae: 705.8392 - val_loss: 7115225.5000 - val_mae: 1531.1351\n",
            "Epoch 900/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1847840.0000 - mae: 698.9122 - val_loss: 8443693.0000 - val_mae: 1563.5852\n",
            "Epoch 901/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1725011.3021 - mae: 729.7927 - val_loss: 8186864.5000 - val_mae: 1556.9644\n",
            "Epoch 902/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2114873.8125 - mae: 795.5230 - val_loss: 7890710.0000 - val_mae: 1628.7616\n",
            "Epoch 903/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1135523.3854 - mae: 732.5111 - val_loss: 9491702.0000 - val_mae: 1896.0994\n",
            "Epoch 904/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 2052186.2083 - mae: 940.2254 - val_loss: 7097869.5000 - val_mae: 1482.3524\n",
            "Epoch 905/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1628741.9479 - mae: 753.6128 - val_loss: 9129994.0000 - val_mae: 1845.2435\n",
            "Epoch 906/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1696208.8646 - mae: 888.9742 - val_loss: 8294042.0000 - val_mae: 1633.9626\n",
            "Epoch 907/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1697652.0000 - mae: 723.7848 - val_loss: 8069721.0000 - val_mae: 1623.5087\n",
            "Epoch 908/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1290130.5417 - mae: 718.8843 - val_loss: 8447235.0000 - val_mae: 1563.7578\n",
            "Epoch 909/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2738381.0208 - mae: 1111.3849 - val_loss: 7982219.0000 - val_mae: 1589.6913\n",
            "Epoch 910/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1926796.4167 - mae: 985.1580 - val_loss: 7687850.0000 - val_mae: 1592.0728\n",
            "Epoch 911/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1997643.2292 - mae: 803.7496 - val_loss: 7960116.0000 - val_mae: 1774.3162\n",
            "Epoch 912/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 2886131.1458 - mae: 1032.2276 - val_loss: 8951289.0000 - val_mae: 1812.5165\n",
            "Epoch 913/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2541438.0938 - mae: 1066.8735 - val_loss: 9075579.0000 - val_mae: 1912.3060\n",
            "Epoch 914/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3367881.4375 - mae: 1317.1783 - val_loss: 11528404.0000 - val_mae: 2260.5476\n",
            "Epoch 915/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5485283.4792 - mae: 1555.6632 - val_loss: 10117398.0000 - val_mae: 1895.2319\n",
            "Epoch 916/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4366686.6875 - mae: 1381.9717 - val_loss: 9425279.0000 - val_mae: 2031.3998\n",
            "Epoch 917/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 5250677.6250 - mae: 1498.1822 - val_loss: 7462580.0000 - val_mae: 1783.3739\n",
            "Epoch 918/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3639902.2917 - mae: 1407.7553 - val_loss: 9031308.0000 - val_mae: 1797.1243\n",
            "Epoch 919/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3381781.3958 - mae: 1104.7712 - val_loss: 7743986.0000 - val_mae: 1648.6292\n",
            "Epoch 920/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2470921.2500 - mae: 940.3991 - val_loss: 7550597.0000 - val_mae: 1600.9686\n",
            "Epoch 921/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2901334.9167 - mae: 873.9875 - val_loss: 9471017.0000 - val_mae: 1790.6718\n",
            "Epoch 922/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1791334.5312 - mae: 946.3370 - val_loss: 7653737.0000 - val_mae: 1660.9180\n",
            "Epoch 923/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1787688.4479 - mae: 964.4411 - val_loss: 8666989.0000 - val_mae: 1748.0862\n",
            "Epoch 924/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1893991.6354 - mae: 890.1871 - val_loss: 7198179.0000 - val_mae: 1550.8467\n",
            "Epoch 925/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1414053.5104 - mae: 749.0103 - val_loss: 7708975.5000 - val_mae: 1534.0229\n",
            "Epoch 926/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 851970.9583 - mae: 652.2066 - val_loss: 7395095.0000 - val_mae: 1549.8495\n",
            "Epoch 927/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1442756.9010 - mae: 751.5805 - val_loss: 8178208.5000 - val_mae: 1642.6033\n",
            "Epoch 928/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2692699.6667 - mae: 791.0440 - val_loss: 7111073.5000 - val_mae: 1493.0116\n",
            "Epoch 929/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1147581.2865 - mae: 605.0426 - val_loss: 7737134.0000 - val_mae: 1503.9806\n",
            "Epoch 930/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3229541.3333 - mae: 655.9049 - val_loss: 7843827.5000 - val_mae: 1504.9249\n",
            "Epoch 931/1000\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 1539061.5260 - mae: 661.3053 - val_loss: 8046753.5000 - val_mae: 1514.4846\n",
            "Epoch 932/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1303287.9375 - mae: 683.9998 - val_loss: 8290228.5000 - val_mae: 1582.9861\n",
            "Epoch 933/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1806202.0781 - mae: 686.2047 - val_loss: 7839301.5000 - val_mae: 1583.3685\n",
            "Epoch 934/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 940346.5521 - mae: 614.7953 - val_loss: 7770523.5000 - val_mae: 1527.5123\n",
            "Epoch 935/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 742359.5469 - mae: 595.6834 - val_loss: 8140967.0000 - val_mae: 1522.9104\n",
            "Epoch 936/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3215833.1667 - mae: 666.8485 - val_loss: 7988643.0000 - val_mae: 1498.2783\n",
            "Epoch 937/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2320955.8750 - mae: 606.7422 - val_loss: 8156922.0000 - val_mae: 1516.9928\n",
            "Epoch 938/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3274482.8333 - mae: 679.7028 - val_loss: 8635757.0000 - val_mae: 1603.8362\n",
            "Epoch 939/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3377233.5938 - mae: 745.6471 - val_loss: 8434694.0000 - val_mae: 1559.6318\n",
            "Epoch 940/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 980047.1615 - mae: 635.9143 - val_loss: 8121236.0000 - val_mae: 1551.1381\n",
            "Epoch 941/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 949773.8750 - mae: 612.6481 - val_loss: 8210457.0000 - val_mae: 1587.7628\n",
            "Epoch 942/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2409229.0781 - mae: 669.1127 - val_loss: 7911955.0000 - val_mae: 1509.9796\n",
            "Epoch 943/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1226053.7344 - mae: 565.4979 - val_loss: 7763764.0000 - val_mae: 1486.8956\n",
            "Epoch 944/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 662752.3151 - mae: 556.8519 - val_loss: 8482352.0000 - val_mae: 1522.2037\n",
            "Epoch 945/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1230031.8047 - mae: 572.3268 - val_loss: 8265413.5000 - val_mae: 1537.1849\n",
            "Epoch 946/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 735033.8438 - mae: 546.6783 - val_loss: 7805674.0000 - val_mae: 1485.3527\n",
            "Epoch 947/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1234832.2786 - mae: 580.6790 - val_loss: 8630569.0000 - val_mae: 1605.4635\n",
            "Epoch 948/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 914047.6120 - mae: 596.6988 - val_loss: 8091683.0000 - val_mae: 1525.6021\n",
            "Epoch 949/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1421647.5286 - mae: 588.3657 - val_loss: 8361809.5000 - val_mae: 1532.8340\n",
            "Epoch 950/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 818395.7344 - mae: 543.2221 - val_loss: 7965096.5000 - val_mae: 1514.5280\n",
            "Epoch 951/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1481828.4792 - mae: 606.8901 - val_loss: 8445103.0000 - val_mae: 1548.0901\n",
            "Epoch 952/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1921951.0807 - mae: 603.5121 - val_loss: 8470202.0000 - val_mae: 1568.2092\n",
            "Epoch 953/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1749171.1875 - mae: 660.2857 - val_loss: 8387175.5000 - val_mae: 1565.3505\n",
            "Epoch 954/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1089309.8984 - mae: 580.1703 - val_loss: 8180378.0000 - val_mae: 1506.0828\n",
            "Epoch 955/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3160457.1875 - mae: 616.6923 - val_loss: 7754477.0000 - val_mae: 1510.1543\n",
            "Epoch 956/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1911628.8672 - mae: 597.6325 - val_loss: 8970706.0000 - val_mae: 1683.2006\n",
            "Epoch 957/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3467023.3542 - mae: 785.9129 - val_loss: 8763900.0000 - val_mae: 1579.3790\n",
            "Epoch 958/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1970005.7266 - mae: 642.4657 - val_loss: 8160590.5000 - val_mae: 1535.8920\n",
            "Epoch 959/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 805217.9375 - mae: 582.0023 - val_loss: 7802858.0000 - val_mae: 1562.8934\n",
            "Epoch 960/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 900942.9167 - mae: 630.7176 - val_loss: 8443590.0000 - val_mae: 1658.0422\n",
            "Epoch 961/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3543623.3854 - mae: 830.2103 - val_loss: 8795902.0000 - val_mae: 1670.9315\n",
            "Epoch 962/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1301048.3958 - mae: 697.3630 - val_loss: 7955064.5000 - val_mae: 1525.5607\n",
            "Epoch 963/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1674104.8464 - mae: 736.5442 - val_loss: 8985033.0000 - val_mae: 1579.5181\n",
            "Epoch 964/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1968858.6042 - mae: 644.1914 - val_loss: 7924102.5000 - val_mae: 1521.2985\n",
            "Epoch 965/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1899650.5938 - mae: 604.9871 - val_loss: 8268634.5000 - val_mae: 1539.9111\n",
            "Epoch 966/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1640933.0260 - mae: 598.9720 - val_loss: 8258229.5000 - val_mae: 1535.9412\n",
            "Epoch 967/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3198968.1979 - mae: 642.6942 - val_loss: 8344019.5000 - val_mae: 1549.5181\n",
            "Epoch 968/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 744197.4661 - mae: 550.1860 - val_loss: 8259145.0000 - val_mae: 1517.8169\n",
            "Epoch 969/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3173087.1042 - mae: 633.4267 - val_loss: 8243931.0000 - val_mae: 1538.9259\n",
            "Epoch 970/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1214494.1641 - mae: 569.2315 - val_loss: 8132998.0000 - val_mae: 1535.0889\n",
            "Epoch 971/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1751429.5573 - mae: 683.7847 - val_loss: 8865873.0000 - val_mae: 1617.4421\n",
            "Epoch 972/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2063663.3333 - mae: 700.0279 - val_loss: 8036432.0000 - val_mae: 1515.6445\n",
            "Epoch 973/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1119600.1042 - mae: 704.0044 - val_loss: 7319226.5000 - val_mae: 1476.0967\n",
            "Epoch 974/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1342205.7083 - mae: 708.2631 - val_loss: 8489944.0000 - val_mae: 1534.6351\n",
            "Epoch 975/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1010682.1875 - mae: 729.4450 - val_loss: 8069023.0000 - val_mae: 1555.2921\n",
            "Epoch 976/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1118235.2188 - mae: 707.4996 - val_loss: 8847529.0000 - val_mae: 1797.1543\n",
            "Epoch 977/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2095350.3073 - mae: 845.0901 - val_loss: 8985442.0000 - val_mae: 1818.5734\n",
            "Epoch 978/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3995612.7083 - mae: 999.7010 - val_loss: 8455772.0000 - val_mae: 1577.7828\n",
            "Epoch 979/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 914705.8802 - mae: 689.1131 - val_loss: 8697308.0000 - val_mae: 1603.3230\n",
            "Epoch 980/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3347410.1875 - mae: 743.3180 - val_loss: 8514107.0000 - val_mae: 1563.8434\n",
            "Epoch 981/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1400409.2500 - mae: 584.3171 - val_loss: 7758953.0000 - val_mae: 1494.6783\n",
            "Epoch 982/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1565540.0260 - mae: 560.1260 - val_loss: 8130745.5000 - val_mae: 1553.3757\n",
            "Epoch 983/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 878915.7161 - mae: 589.4405 - val_loss: 8486279.0000 - val_mae: 1602.7526\n",
            "Epoch 984/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1068912.4844 - mae: 630.7262 - val_loss: 8277613.0000 - val_mae: 1532.4545\n",
            "Epoch 985/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1652862.3047 - mae: 623.4402 - val_loss: 7868665.5000 - val_mae: 1507.2258\n",
            "Epoch 986/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1877766.5703 - mae: 578.6242 - val_loss: 8625194.0000 - val_mae: 1558.4019\n",
            "Epoch 987/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 875407.7943 - mae: 586.8565 - val_loss: 8688536.0000 - val_mae: 1620.0481\n",
            "Epoch 988/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1536636.2708 - mae: 669.7121 - val_loss: 7947755.5000 - val_mae: 1502.6071\n",
            "Epoch 989/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3296126.2500 - mae: 706.2881 - val_loss: 7891249.0000 - val_mae: 1510.7250\n",
            "Epoch 990/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3225383.6771 - mae: 659.8345 - val_loss: 8029430.5000 - val_mae: 1555.9944\n",
            "Epoch 991/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 777990.9505 - mae: 577.6989 - val_loss: 7636131.0000 - val_mae: 1627.5620\n",
            "Epoch 992/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1100404.3542 - mae: 693.3111 - val_loss: 8500226.0000 - val_mae: 1639.8414\n",
            "Epoch 993/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1361873.9427 - mae: 662.0429 - val_loss: 7709398.5000 - val_mae: 1485.6718\n",
            "Epoch 994/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1919127.0026 - mae: 615.9684 - val_loss: 7987132.5000 - val_mae: 1524.9819\n",
            "Epoch 995/1000\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 857882.8151 - mae: 627.3009 - val_loss: 7843284.5000 - val_mae: 1509.5551\n",
            "Epoch 996/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1335526.0260 - mae: 647.7422 - val_loss: 7852641.0000 - val_mae: 1526.9766\n",
            "Epoch 997/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1882641.0365 - mae: 742.1357 - val_loss: 8277323.5000 - val_mae: 1667.3572\n",
            "Epoch 998/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1565184.6406 - mae: 745.9230 - val_loss: 7905067.0000 - val_mae: 1508.0524\n",
            "Epoch 999/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 698710.5625 - mae: 575.2286 - val_loss: 7674932.5000 - val_mae: 1482.0610\n",
            "Epoch 1000/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1456233.5260 - mae: 607.7450 - val_loss: 7959019.5000 - val_mae: 1573.2677\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 10858260.0000 - mae: 1595.7057\n",
            "loss, mae :  10858260.0 1595.7056884765625\n",
            "RMSE :  3295.187507476939\n",
            "R2 :  0.8933427154200366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-15348fa709a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0mx1_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0mx2_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx2_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m \u001b[0mx1_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0mx2_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx2_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eikfzi8ZT_rW"
      },
      "source": [
        "# 로컬 파일 시스템"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaCkyg5CV5jF"
      },
      "source": [
        "## 로컬 파일 시스템의 파일 업로드\n",
        "\n",
        "<code>files.upload</code>는 업로드된 파일의 사전을 반환합니다.\n",
        "사전은 업로드된 파일 이름에 따라 키가 지정되며, 값은 업로드된 데이터를 표시합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz-jH8T_Uk2c"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hauvGV4hV-Mh"
      },
      "source": [
        "## 로컬 파일 시스템으로 파일 다운로드\n",
        "\n",
        "<code>files.download</code>는 파일의 브라우저 다운로드를 로컬 컴퓨터로 호출합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2E4EKhCWEC5"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "with open('example.txt', 'w') as f:\n",
        "  f.write('some content')\n",
        "\n",
        "files.download('example.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2W5A2px3doP"
      },
      "source": [
        "# Google 드라이브\n",
        "\n",
        "다음과 같은 여러 가지 방법으로 드라이브에 있는 파일에 액세스할 수 있습니다.\n",
        "- 런타임 가상 머신에 Google 드라이브 마운트\n",
        "- <a href=\"https://gsuitedevs.github.io/PyDrive/docs/build/html/index.html\">PyDrive</a>와 같은 API에 래퍼 사용\n",
        "- <a href=\"https://developers.google.com/drive/v3/web/about-sdk\">네이티브 REST API</a> 사용\n",
        "\n",
        "\n",
        "\n",
        "각각의 예시는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u22w3BFiOveA"
      },
      "source": [
        "## 로컬에 Google 드라이브 마운트하기\n",
        "\n",
        "아래의 예시에서는 승인 코드를 사용해 런타임에 Google 드라이브를 마운트하는 방법 및 이 드라이브에서 파일을 쓰고 읽는 방법을 보여 줍니다. 이 예시를 실행하면 <a href=\"https://drive.google.com/\">https://drive.google.com/</a>에 새 파일&#40;<code>foo.txt</code>&#41;이 표시됩니다.\n",
        "\n",
        "이 방법으로는 파일을 읽고, 쓰고 이동하는 작업만 가능하므로 프로그래매틱 방식으로 공유 설정이나 기타 메타데이터를 수정하려면 아래의 다른 옵션 중 하나를 사용하세요.\n",
        "\n",
        "<strong>참고:</strong> 파일 브라우저의 '드라이브 마운트' 버튼을 사용할 때 현재 사용자만 수정한 메모장에 대해서는 인증 코드는 필요하지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "RWSJpsyKqHjH",
        "outputId": "15bd239f-5a6a-447d-dd22-01ee5398b991"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XDg9OBaYqRMd",
        "outputId": "5df8b65d-20d2-4956-b8a7-e99d4579d567"
      },
      "source": [
        "with open('/content/drive/My Drive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat /content/drive/My\\ Drive/foo.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Google Drive!"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "D78AM1fFt2ty",
        "outputId": "f7117bc5-2ffd-4c0a-8809-f9fed79b4682"
      },
      "source": [
        "drive.flush_and_unmount()\n",
        "print('All changes made in this colab session should now be visible in Drive.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All changes made in this colab session should now be visible in Drive.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7taylj9wpsA2"
      },
      "source": [
        "## PyDrive\n",
        "\n",
        "아래 예시에서는 PyDrive를 사용한 인증 및 파일 업로드/다운로드 방법을 확인할 수 있습니다. <a href=\"https://gsuitedevs.github.io/PyDrive/docs/build/html/index.html\">PyDrive 도움말</a>에서 더 많은 예시를 살펴보세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU5b6dlRwUQk"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkHZtRhm09QS"
      },
      "source": [
        "PyDrive 클라이언트를 인증하고 만듭니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w7lrGcW08Ds"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF3Topk31DCF"
      },
      "source": [
        "텍스트 파일을 만들고 업로드합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "vBuUW-q41tb7",
        "outputId": "e5558ef2-e5db-4e4e-9f01-186e9dd4bc26"
      },
      "source": [
        "uploaded = drive.CreateFile({'title': 'Sample upload.txt'})\n",
        "uploaded.SetContentString('Sample upload file content')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 14vDAdqp7BSCQnoougmgylBexIr2AQx2T\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbOFN3d_1tcG"
      },
      "source": [
        "ID별로 파일을 로드하고 파일 내용을 출력합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "eFOvsAYk1tcH",
        "outputId": "c8f0e09a-f873-4c43-8211-5f0a0c5e0e5f"
      },
      "source": [
        "downloaded = drive.CreateFile({'id': uploaded.get('id')})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded content \"Sample upload file content\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRQ5_yMcqJiV"
      },
      "source": [
        "## Drive REST API\n",
        "\n",
        "Drive API를 사용하려면 인증한 다음 API 클라이언트를 구성해야 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-exJtdG3XwJ"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDLm7MHQEr2U"
      },
      "source": [
        "이 클라이언트를 사용하면 <a href=\"https://developers.google.com/drive/v3/reference/\">Google Drive API 참조</a>에 있는 모든 기능을 사용할 수 있습니다. 기능의 예시는 다음과 같습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRFyEsdfBxJ9"
      },
      "source": [
        "### Python 데이터로 새 드라이브 파일 만들기\n",
        "\n",
        "먼저 업로드할 로컬 파일을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "F1-nafvN-NwW",
        "outputId": "4466d27b-edd0-4ef1-8a10-0e180a231af2"
      },
      "source": [
        "with open('/tmp/to_upload.txt', 'w') as f:\n",
        "  f.write('my sample file')\n",
        "\n",
        "print('/tmp/to_upload.txt contains:')\n",
        "!cat /tmp/to_upload.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/to_upload.txt contains:\n",
            "my sample file"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5X77CZ5_G-C"
      },
      "source": [
        "<a href=\"https://developers.google.com/drive/v3/reference/files/create\"><code>files.create</code></a> 방식을 사용해 업로드합니다. 업로드 파일에 관한 추가 정보는 <a href=\"https://developers.google.com/drive/v3/web/manage-uploads\">개발자 도움말</a>에서 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3Jv6jh6HEpP8",
        "outputId": "cfc1186f-68a1-4620-a18f-99bc6d83e82e"
      },
      "source": [
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "file_metadata = {\n",
        "  'name': 'Sample file',\n",
        "  'mimeType': 'text/plain'\n",
        "}\n",
        "media = MediaFileUpload('/tmp/to_upload.txt', \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "created = drive_service.files().create(body=file_metadata,\n",
        "                                       media_body=media,\n",
        "                                       fields='id').execute()\n",
        "print('File ID: {}'.format(created.get('id')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ID: 1Cw9CqiyU6zbXFD9ViPZu_3yX-sYF4W17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5VyISCKFrqU"
      },
      "source": [
        "위의 셀을 실행하면 <a href=\"https://drive.google.com/\">https://drive.google.com/</a>에 'Sample file'이라는 새 파일이 표시됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3KX0Sm0E2sF"
      },
      "source": [
        "### 드라이브 파일 데이터를 Python으로 다운로드\n",
        "\n",
        "위에서 업로드한 파일을 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "hEzpzWYWsYKg",
        "outputId": "57c1ac51-a8ec-497e-db77-f34fd974ac2f"
      },
      "source": [
        "file_id = created.get('id')\n",
        "\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "downloaded = io.BytesIO()\n",
        "downloader = MediaIoBaseDownload(downloaded, request)\n",
        "done = False\n",
        "while done is False:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, done = downloader.next_chunk()\n",
        "\n",
        "downloaded.seek(0)\n",
        "print('Downloaded file contents are: {}'.format(downloaded.read()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded file contents are: b'my sample file'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImztleG2Ciae"
      },
      "source": [
        "다른 파일을 다운로드하려면 위의 <code>file&#95;id</code>를 파일의 ID로 설정하세요. ID의 형식은 '1uBtlaggVyWshwcyP6kEI-y&#95;W3P8D26sz'와 같습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOm9PFrT8mGG"
      },
      "source": [
        "# Google 스프레드시트\n",
        "\n",
        "아래 예시는 오픈소스 <a href=\"https://github.com/burnash/gspread\"><code>gspread</code></a> 라이브러리를 사용해 Google 스프레드시트와 상호작용합니다.\n",
        "\n",
        "먼저 <code>pip</code>를 사용해 패키지를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwu_sWHv4jEo"
      },
      "source": [
        "!pip install --upgrade gspread"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzi9VsEqzI-o"
      },
      "source": [
        "라이브러리를 가져오고 인증한 다음 스프레드시트에 인터페이스를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d0xJz3VzLOo"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjrZQUrt6kKj"
      },
      "source": [
        "다음은 몇 가지 <code>gspread</code> 예시입니다. 추가 예시는 <a href=\"https://github.com/burnash/gspread#more-examples\"><code>gspread</code> GitHub 페이지</a>에서 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgXqE02UofZG"
      },
      "source": [
        "## Python 데이터로 새 시트 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnnYKhGfzGeP"
      },
      "source": [
        "sh = gc.create('My cool spreadsheet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9Ia9JVc6Zvk"
      },
      "source": [
        "위의 셀을 실행하면 <a href=\"https://sheets.google.com/\">https://sheets.google.com</a>에 'My cool spreadsheet'라는 새 스프레드시트가 표시됩니다.\n",
        "\n",
        "새 시트를 열고 몇 가지 데이터를 무작위로 추가합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "ASdgLIt2s-ux",
        "outputId": "68c9eed9-bab9-4169-c5b7-769f7b9e0194"
      },
      "source": [
        "worksheet = gc.open('My cool spreadsheet').sheet1\n",
        "\n",
        "cell_list = worksheet.range('A1:C2')\n",
        "\n",
        "import random\n",
        "for cell in cell_list:\n",
        "  cell.value = random.randint(1, 10)\n",
        "\n",
        "worksheet.update_cells(cell_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1dsQeN0YzXuM387l_CuyEbsYzL2ew9TJFzR-E-RQnwxs',\n",
              " 'updatedCells': 6,\n",
              " 'updatedColumns': 3,\n",
              " 'updatedRange': 'Sheet1!A1:C2',\n",
              " 'updatedRows': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9q0pp33dckN"
      },
      "source": [
        "## 시트의 데이터를 Pandas DataFrame으로 Python에 다운로드\n",
        "\n",
        "위에서 삽입한 무작위 데이터를 다시 읽고 결과를 <a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\">Pandas DataFrame</a>으로 변환합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "J4QxBareshEV",
        "outputId": "baf17cd6-3c3d-4a34-b1f9-642516cb2bfe"
      },
      "source": [
        "worksheet = gc.open('My cool spreadsheet').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "print(rows)\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame.from_records(rows)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['6', '3', '4'], ['7', '2', '1']]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/81868506e94e6988/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"6\",\n\"3\",\n\"4\"],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"7\",\n\"2\",\n\"1\"]],\n        columns: [[\"number\", \"index\"], [\"string\", \"0\"], [\"string\", \"1\"], [\"string\", \"2\"]],\n        rowsPerPage: 25,\n      });\n    ",
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1  2\n",
              "0  6  3  4\n",
              "1  7  2  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7c8WYyQdh5i"
      },
      "source": [
        "# Google Cloud Storage&#40;GCS&#41;\n",
        "\n",
        "GCS와 함께 Colaboratory를 사용하려면 <a href=\"https://cloud.google.com/storage/docs/projects\">Google Cloud 프로젝트</a>를 만들거나 기존 프로젝트를 사용해야 합니다.\n",
        "\n",
        "아래에서 프로젝트 ID를 지정하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYC5CyAbAtU7"
      },
      "source": [
        "project_id = 'Your_project_ID_here'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iRYBSVCbAlK"
      },
      "source": [
        "GCS의 파일은 <a href=\"https://cloud.google.com/storage/docs/key-terms#buckets\">버킷</a>에 보관됩니다.\n",
        "\n",
        "버킷에는 전역 고유 이름이 필요하므로 여기에서 하나 생성하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgjL1e0ua-kN"
      },
      "source": [
        "import uuid\n",
        "bucket_name = 'colab-sample-bucket-' + str(uuid.uuid1())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OtHMRVda9pJ"
      },
      "source": [
        "GCS에 액세스하려면 인증이 필요합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQX0hbfYaEKc"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLPAbDDFaLXU"
      },
      "source": [
        "GCS는 <code>gsutil</code> 명령줄 유틸리티 또는 네이티브 Python API를 통해 액세스할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvuZEyRQXmyS"
      },
      "source": [
        "## `gsutil`\n",
        "\n",
        "먼저 <code>gcloud</code>를 사용해 위에서 지정한 프로젝트를 사용할 수 있도록 <code>gsutil</code>을 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TpnuFITI6Tzu",
        "outputId": "04f1dd6d-4d7e-4264-b37b-1e8f645d6d38"
      },
      "source": [
        "!gcloud config set project {project_id}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAM6vyXAfVUj"
      },
      "source": [
        "업로드할 로컬 파일을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "LADpx7LReOMk",
        "outputId": "46db7cfa-9ad8-405b-f715-b466a3b2cb7a"
      },
      "source": [
        "with open('/tmp/to_upload.txt', 'w') as f:\n",
        "  f.write('my sample file')\n",
        "\n",
        "print('/tmp/to_upload.txt contains:')\n",
        "!cat /tmp/to_upload.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/to_upload.txt contains:\n",
            "my sample file"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSz0aInzWXFI"
      },
      "source": [
        "파일을 업로드할 버킷을 만듭니다&#40;<a href=\"https://cloud.google.com/storage/docs/gsutil/commands/mb\">도움말</a>&#41;."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Bcpvh_R_6jKB",
        "outputId": "e1c132b8-6a5c-46db-b1fa-f5768089890c"
      },
      "source": [
        "!gsutil mb gs://{bucket_name}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating gs://colab-sample-bucket-44971372-baaf-11e7-ae30-0242ac110002/...\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHPM16gWWNvn"
      },
      "source": [
        "파일을 새 버킷으로 복사합니다&#40;<a href=\"https://cloud.google.com/storage/docs/gsutil/commands/cp\">도움말</a>&#41;."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "L5cMl7XV65be",
        "outputId": "bb51e51d-7f5f-4e2b-935c-203b8d314115"
      },
      "source": [
        "!gsutil cp /tmp/to_upload.txt gs://{bucket_name}/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file:///tmp/to_upload.txt [Content-Type=text/plain]...\n",
            "/ [1 files][   14.0 B/   14.0 B]                                                \n",
            "Operation completed over 1 objects/14.0 B.                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAPlMk6nWKNm"
      },
      "source": [
        "모든 항목이 제대로 작동하도록 새롭게 복사한 파일의 내용을 덤프합니다&#40;<a href=\"https://cloud.google.com/storage/docs/gsutil/commands/cat\">도움말</a>&#41;.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pJGU6gX-7M-N",
        "outputId": "38db2bd3-0879-4a2e-8f41-c9495ba570a9"
      },
      "source": [
        "!gsutil cat gs://{bucket_name}/to_upload.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my sample file"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "height": 34
        },
        "id": "qoectKiGOABf",
        "outputId": "97b483ac-c2b1-46f0-f4ac-61b3701a8c89"
      },
      "source": [
        "#@markdown 업로드가 완료되면 프로젝트의 Cloud Console Storage 브라우저에 데이터가 표시됩니다.\n",
        "print('https://console.cloud.google.com/storage/browser?project=' + project_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://console.cloud.google.com/storage/browser?project=Your_project_ID_here\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2CWQGIghDux"
      },
      "source": [
        "마지막으로 위 예시에 방금 업로드한 파일을 다운로드해 보겠습니다. <code>gsutil cp</code> 명령어에서 순서를 반대로 바꾸기만 하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "lPdTf-6O73ll",
        "outputId": "a6da299e-00ff-42a7-f845-9a93a4ccce61"
      },
      "source": [
        "!gsutil cp gs://{bucket_name}/to_upload.txt /tmp/gsutil_download.txt\n",
        "  \n",
        "# 전송이 제대로 작동하는지 확인하기 위해 결과를 출력합니다.\n",
        "!cat /tmp/gsutil_download.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://colab-sample-bucket483f20dc-baaf-11e7-ae30-0242ac110002/to_upload.txt...\n",
            "/ [1 files][   14.0 B/   14.0 B]                                                \n",
            "Operation completed over 1 objects/14.0 B.                                       \n",
            "my sample file"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ENMqxq25szn"
      },
      "source": [
        "## Python API\n",
        "\n",
        "다음 스니펫은 API의 추가적인 사용 사례를 보여 주는 <a href=\"https://github.com/GoogleCloudPlatform/storage-file-transfer-json-python/blob/master/chunked_transfer.py\">대규모 예시</a>를 기반으로 합니다.\n",
        "\n",
        "먼저 서비스 클라이언트를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkJ5ShIgceqI"
      },
      "source": [
        "from googleapiclient.discovery import build\n",
        "gcs_service = build('storage', 'v1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1Hyoh07gQHY"
      },
      "source": [
        "업로드할 로컬 파일을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "height": 51
        },
        "id": "s1htTNVlgQHe",
        "outputId": "1a002b58-6c4d-46d0-9572-a43b9bccbfe8"
      },
      "source": [
        "with open('/tmp/to_upload.txt', 'w') as f:\n",
        "  f.write('my sample file')\n",
        "\n",
        "print('/tmp/to_upload.txt contains:')\n",
        "!cat /tmp/to_upload.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/to_upload.txt contains:\n",
            "my sample file"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJKBHaUlgDhl"
      },
      "source": [
        "위에서 지정된 프로젝트에 버킷을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YFVbF4cdhd9Y",
        "outputId": "ffa2a4ec-ee02-4fc2-8ed4-a4d73d04e6be"
      },
      "source": [
        "# 위의 gsutil 예시와 다른 전역 고유 버킷 이름을 사용하세요.\n",
        "import uuid\n",
        "bucket_name = 'colab-sample-bucket-' + str(uuid.uuid1())\n",
        "\n",
        "body = {\n",
        "  'name': bucket_name,\n",
        "  # For a full list of locations, see:\n",
        "  # https://cloud.google.com/storage/docs/bucket-locations\n",
        "  'location': 'us',\n",
        "}\n",
        "gcs_service.buckets().insert(project=project_id, body=body).execute()\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppkrR7p4mx_P"
      },
      "source": [
        "새롭게 만든 버킷에 파일을 업로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cFAq-F2af5TJ",
        "outputId": "d07f7059-5767-4d58-ac71-e457a76e8c07"
      },
      "source": [
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload('/tmp/to_upload.txt', \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket=bucket_name, \n",
        "                                       name='to_upload.txt',\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "height": 34
        },
        "id": "Lvz1BspfpvTl",
        "outputId": "97b483ac-c2b1-46f0-f4ac-61b3701a8c89"
      },
      "source": [
        "#@markdown 업로드가 완료되면 프로젝트의 Cloud Console Storage 브라우저에 데이터가 표시됩니다.\n",
        "print('https://console.cloud.google.com/storage/browser?project=' + project_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://console.cloud.google.com/storage/browser?project=Your_project_ID_here\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6aWjfTv7bit"
      },
      "source": [
        "방금 업로드한 파일을 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "z1_FuDjAozF1",
        "outputId": "ab14cf25-7b51-41c9-d88c-9a94f5c79dfc"
      },
      "source": [
        "from apiclient.http import MediaIoBaseDownload\n",
        "\n",
        "with open('/tmp/downloaded_from_gcs.txt', 'wb') as f:\n",
        "  request = gcs_service.objects().get_media(bucket=bucket_name,\n",
        "                                            object='to_upload.txt')\n",
        "  media = MediaIoBaseDownload(f, request)\n",
        "\n",
        "  done = False\n",
        "  while not done:\n",
        "    # _ is a placeholder for a progress object that we ignore.\n",
        "    # (Our file is small, so we skip reporting progress.)\n",
        "    _, done = media.next_chunk()\n",
        "\n",
        "print('Download complete')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnjWcDFogdY2"
      },
      "source": [
        "다운로드된 파일을 검사합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "height": 34
        },
        "id": "DxLyhaiBpAGX",
        "outputId": "eb379e18-a6bf-4af2-caf4-f8b9c57f4a80"
      },
      "source": [
        "!cat /tmp/downloaded_from_gcs.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my sample file"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}